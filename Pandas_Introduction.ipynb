{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f58b7dcc-0aa8-4dca-8ec0-c4cb3db1312b",
   "metadata": {},
   "source": [
    "# Introduction to Pandas\n",
    "\n",
    "**Pandas** is a python library that has been created by **Wes McKinney** in 2007 on top of the **Numpy** library, and had become open sourced by the end of 2009. It is widely used in data science, machine learning and data analysis tasks. The name is derived from the term **\"PANel DAta\"** (tabular data), an econometrics term for data sets that include observations over multiple time periods for the same individuals. ([wikipedia](https://en.wikipedia.org/wiki/Pandas_(software)))\n",
    "\n",
    "**Pandas** works well together with other librairies such as **Matplotlib / Seaborn** and, of course, **Numpy**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dc562f-6c3f-4990-876d-5a7ed2eb0292",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"files/pandas_numpy_matplotlib_seaborn.png\" width=\"100%\" align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f9db81-31fe-4489-a401-1ab5e94f2e8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd # We'll use pd as the alias\n",
    "import numpy as np # and np as alias for numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55761509-6ba8-4909-bf4e-1a37d988dcbc",
   "metadata": {},
   "source": [
    "# DataFrame\n",
    "\n",
    "A Pandas DataFrame is a two-dimensional, size-mutable, and highly flexible data structure for data manipulation and analysis in Python. The DataFrame is often compared to a spreadsheet or a SQL table, as it organizes data into rows and columns, making it easy to work with structured data.\n",
    "\n",
    "Key characteristics of a Pandas DataFrame:\n",
    "\n",
    "- **Two-Dimensional**: A DataFrame consists of rows and columns, much like a table in a relational database or an Excel spreadsheet.\n",
    "\n",
    "- **Size-Mutable**: You can add or remove rows and columns from a DataFrame, making it adaptable to changing data.\n",
    "\n",
    "- **Labeled Axes**: Both rows and columns have labels (index and column names), allowing for easy identification and indexing of data.\n",
    "\n",
    "- **Mixed Data Types**: A DataFrame can contain data of different types (e.g., integers, floats, strings) in different columns, or inside the same column.\n",
    "\n",
    "- **Missing Data Handling**: DataFrames can handle missing or NaN (Not-a-Number) values gracefully, providing tools for detecting, removing, or imputing missing data.\n",
    "\n",
    "- **Operations**: DataFrames support a wide range of data operations, including filtering, grouping, aggregation, pivoting, merging, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2570caad-4caa-4098-8204-3f580b889c60",
   "metadata": {},
   "source": [
    "## Creating a DataFrame\n",
    "\n",
    "Pandas can create DataFrames from many differents file formats including :\n",
    "\n",
    "- CSV (comma separated value)\n",
    "- Excel (XLS and XLSX)\n",
    "- JSON (Java Script Object Notation)\n",
    "- HTML (Tables)\n",
    "- SQL (Databases)\n",
    "- Parquet\n",
    "- HDF5 (Hierarchical Data Format)\n",
    "- Feather\n",
    "- Stata\n",
    "- SAS\n",
    "- Google BigQuery\n",
    "- Clipboard\n",
    "- Python Dictionnaries\n",
    "- URLs (HTTP, FTP, etc.)\n",
    "- ... And many more"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebbc4a0-9f29-425d-a4ca-34f64cb96687",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fake dataset\n",
    "\n",
    "Let's create a DataFrame from a CSV file stored inside the \"data\" folder and named \"fake.csv\". We'll use this fake dataset later to demonstrate some of the Pandas functions. Let's store it in a variable named : **\"fake_df\"**.\n",
    "\n",
    "**Note**: Here we're using a naming convention named **\"suffix Hungarian notation\"**, meaning the type of the object is included at the end of its name. And, of course, \"df\" is short for \"DataFrame\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b012afd5-eaa6-4694-a99a-b3586d7d6e26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df = pd.read_csv(\"data/fake.csv\")\n",
    "\n",
    "fake_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fe3ff0-c201-4c40-b53e-fede9073649d",
   "metadata": {},
   "source": [
    "If you run the cell above, you can tell right away that \"fake_df\" is a **DataFrame**: columns names and indices are in bold-style. And if you mouse over the DataFrame, rows are highlighted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afa9593-f9bc-4a90-9a35-2b84d79524b9",
   "metadata": {},
   "source": [
    "## Reading a CSV file : the \"Survey Data\"\n",
    "\n",
    "**>>>** Use the ``pd.read_csv()`` function to read the CSV file named \"survey.csv\" which is located inside the \"data\" folder. Store the result in a new DataFrame named \"df\".\n",
    "\n",
    "If you try to read a CSV file and Pandas returns an error, open the file with jupyter lab or a text editor (VS Code, Notepad++ etc.) and examine it to find the source of the error. The most common errors when reading a csv file are:\n",
    "\n",
    "- The **filepath** was not properly given to the function. The easiest way is to move the file you want to read in the same directory than your notebook file (or in a subfolder named \"data\").\n",
    "\n",
    "- A wrong **field separator**, by default Pandas assumes that it is the \",\" character. In this case specify the separator (= delimiter) with the argument \"sep\".\n",
    "\n",
    "- A bad **\"quotechar\"**, a character used to denote the start and end of a quoted item. Quoted items can include the delimiter and it will be ignored. In this case specify it with the \"quotechar\" argument.\n",
    "\n",
    "- Bad file **encoding**. The \"utf-8\" standard is the most common, but sometimes the files are in other formats like \"cp1252\" for example. In this case specify the encoding with the \"encoding\" argument.\n",
    "\n",
    "- The presence of **extra lines** at the beginning or at the end of the file. In this case use the \"skiprows\" or \"skipfooter\" arguments to ignore these lines.\n",
    "\n",
    "**NOTE**: Do **NOT** open the file with the sofware \"Excel\", it may corrupt your file and make it unreadable, even if you don't save the modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f91dd39-4729-4510-8fd4-22bd2bcafcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4894468-6e20-48bd-a368-e07ee1e8eb3e",
   "metadata": {},
   "source": [
    "# First things to do\n",
    "\n",
    "## The `.shape` property\n",
    "\n",
    "We now have two DataFrames \"fake_df\" and \"df\". Let's take a look at our they're shaped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8952bb-2e50-461a-8f0d-a2407415534d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc778ab-4b9c-47c1-9e23-6e60c9577ee2",
   "metadata": {
    "tags": []
   },
   "source": [
    "**>>>** What shape is our df? What does it mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2375ac7-975b-4392-86bf-dec8900ed68a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5875ea1-231b-4f84-8b7b-ead0e304cc50",
   "metadata": {},
   "source": [
    "## The ``.head()`` function\n",
    "\n",
    "It returns the first n rows, default is set to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6765fb02-2c49-4b7b-96b2-91c6ae7b1cb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a84850-46ca-41ad-8306-bac3c4829f8d",
   "metadata": {},
   "source": [
    "**>>>** Use the ``.head()`` function to display the first 2 lines of our df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7116b0b-f256-4ed2-9f77-018f6cf13717",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401c26b4-713d-4a7d-95fa-1f0e8b946c1a",
   "metadata": {},
   "source": [
    "## The `.columns` property\n",
    "\n",
    "It stores the names of our different columns. It is also the index of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9417547b-1377-4feb-8d45-a9a43881d72a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaf55d0-4488-414d-9196-98410dc8f17d",
   "metadata": {
    "tags": []
   },
   "source": [
    "**>>>** What are the columns of our DataFrame? Use a ``for`` loop to print each column name on a different line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120bb727-0a58-4f3d-a0f8-5d8111daa4b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbf9659-ddd8-4a07-99b3-51915c97f2c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The `.index` property\n",
    "\n",
    "It stores the names of the rows (the index)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2fe2b7-507a-421a-a0ee-96af8dd9c3b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "**>>>** What are the rows of our df? Use a ``for`` loop to print each row index on a different line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434b439f-f3fa-4652-8407-54642c813f79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7103be-d382-42fd-b274-b0d418ed0510",
   "metadata": {},
   "source": [
    "## The `.dtypes` property\n",
    "\n",
    "The word `dtypes` stand for \"data types\", it stores the types of our different columns. The type \"object\" is often a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe080a4-de3a-424c-9073-1058ea906151",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7539d74a-cc25-4d1c-a226-630cbf221aa6",
   "metadata": {
    "tags": []
   },
   "source": [
    "**>>>** What are the dtypes of our df?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09233a4-27b2-4315-837a-8ab0c9e5bfcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089403d3-e5c5-4f23-ac85-1e445cf45c3a",
   "metadata": {},
   "source": [
    "## Missing values : the `.isna()` method\n",
    "\n",
    "When you're given a new dataset, it is quite important to check if they are missing values. You can use the ``.isna()`` method, it returns a new DataFrame which has the same size than the original df, but the values are ``True`` if the value is missing and ``False`` if a value exists.\n",
    "\n",
    "That's one of the main strength of python : the outputs of many Pandas functions are also Pandas objects, meaning you can work on your data or your results using the same functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d63f96-8ee1-4257-bd7c-037d7ecc1a45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f085129f-2cc0-4e77-9bff-c3d1c1a3e3d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "**>>>** Use ``.isna()`` on your DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16da66f-16e2-42ca-ab84-1817f19d6eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eeb562a-8e81-41d5-ba27-16f317e69d89",
   "metadata": {},
   "source": [
    "## Apply a function to a DataFrame : ``isna().sum()``\n",
    "\n",
    "The ``.sum()`` method performs a sum on an entire DataFrame. When performing sums, boolean values are treated as 1 if they're ``True`` and 0 if they're ``False``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaf90c2-551b-4179-99c2-24a5c33efe96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edea25a-e192-4601-9b7d-2330709c1dea",
   "metadata": {},
   "source": [
    "**>>>** How many missing values in our DataFrame ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9b8df2-a36e-4e29-bea0-1970528a7c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1486a434-ceae-4d7d-9a0d-05583385e4dd",
   "metadata": {},
   "source": [
    "# Series\n",
    "\n",
    "The output generated by ``.isna().sum()`` is called a Series. A Series is a one-dimensional labeled array-like data structure, it is sometimes referred as \"column\". A Series consists of two main components:\n",
    "\n",
    "- **Values**: This is the actual values contained in the Series, which can be of any data type such as integers, floats, strings, or more complex types.\n",
    "\n",
    "- **Index**: An index is a label or identifier associated with each data point in the Series.\n",
    "\n",
    "DataFrames are a collection of Series, so if you slice your DataFrame using the name of the columns, you'll also get Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422f6c3a-3511-49b8-9b04-e9d68fd33256",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['letter']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3f3b17-16e0-46e8-ae70-24241c19ae64",
   "metadata": {},
   "source": [
    "You can tell it's a Series because there's only one dimension, and, unlike a DataFrame, the output is plain text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85eccab-2620-4866-b255-4ac11cc4d59c",
   "metadata": {},
   "source": [
    "**>>>** Slice the column \"country\" from your DataFrame and display the corresponding Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d08193a-3eeb-4115-b30c-c48ba89887d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efec20ba-9c90-4cc1-9f84-910ed3767572",
   "metadata": {},
   "source": [
    "## Creating or replacing Series\n",
    "\n",
    "Just like a dictionnary, to create or replace a Series you just have to assign it a variable (list, dict, integer, almost any objects...).\n",
    "\n",
    "```python\n",
    "df['my_new_series'] = my_value(s)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9525759-4c0d-48fa-acfa-a0b23131b144",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['one'] = 1\n",
    "fake_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e175db06-f1f6-4d4d-b5b8-9ec227d68687",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['one'] = 999\n",
    "fake_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5ec72a-d3db-4149-835c-d835a087ccd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df[['one', 'two']] = 1\n",
    "fake_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9778e2da-4d75-4ec1-8d75-1e872b63c2ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df[['one', 'two']] = 1, 2 # An implicit tuple\n",
    "fake_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67319b7e-ba24-4a02-b411-6ad5259198c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['three'] = fake_df['one'] + fake_df['two']\n",
    "fake_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f010a02-fbe0-496d-a763-ce22d1b7ee72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['count'] = [el for el in range(fake_df.shape[0])]\n",
    "fake_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23040353-8deb-4fe8-b8fe-e2e08b2677cb",
   "metadata": {},
   "source": [
    "### Dropping a Series\n",
    "\n",
    "There are several ways to \"drop\" (erase / remove / delete) a Series from your DataFrame, one of the easiest is just:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60751b9e-d3a5-4e1d-9a7b-595844fe3173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.drop(columns='one') # This function is not \"in place\" which means we haven't modified \"fake_df\" yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4608925c-518b-4335-9910-40933ed2bff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we're happy with the result\n",
    "# We can replace the old df with the new one\n",
    "fake_df = fake_df.drop(columns='one')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb0f2fd-06b8-4754-9b77-817763ed724c",
   "metadata": {},
   "source": [
    "**/!\\ WATCH OUT !** This time we're not replacing or creating a **Series** we're replacing the whole DataFrame!\n",
    "\n",
    "One can get confused very easily. Luckily if you make a mistake, it's also very easy to go back and re-run the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc509bcc-4ace-43f1-a8b9-70da712de17d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can drop several columns by passing a list.\n",
    "fake_df.drop(columns=['two', 'three', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17afb14c-e8e5-4679-9751-db6ac515bf7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If we're happy with the result\n",
    "# We can replace the old df with the new one\n",
    "fake_df = fake_df.drop(columns=['two', 'three', 'count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bec7a2c-6700-44cd-9e68-c0e20da92616",
   "metadata": {},
   "source": [
    "# Dealing with data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3093926c-7015-498b-8d4b-ac076fe75223",
   "metadata": {},
   "source": [
    "## Setting the right data types\n",
    "\n",
    "Now that we know what is a DataFrame and a Series, and before we start doing something else, it's important that our Series are converted in the right type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc7ceb1-c9b9-43ac-941a-5e49e1802ab0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc597c7-c520-4d2d-8267-9532589f8c8b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Conversion with `.astype()`\n",
    "\n",
    "There are many different types of dtype. Some of them use standard Python format, some are specific to Pandas and others are common to several other languages (PyArrow).\n",
    "\n",
    "Here let's use either:\n",
    "\n",
    "- `'string'` (which is a Pandas type)\n",
    "- `'category'` (also pandas type)\n",
    "- `int` (python type)\n",
    "- `float` (python type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63de3106-fb53-4c58-8bbe-e21c3dc5df04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# One conversion\n",
    "fake_df['letter'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2da2ed-076f-400f-81e7-fdac83d9d871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Several conversions\n",
    "fake_df[['fruit', 'letter']].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e62766-f253-4362-9e0c-586f65994450",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replacing old Series with new ones\n",
    "fake_df[['fruit', 'letter']] = fake_df[['fruit', 'letter']].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba88b606-632a-4d7e-a484-cbad6315be23",
   "metadata": {},
   "source": [
    "## Conversion with a new import\n",
    "\n",
    "The best practice is probably to set the datatypes when importing the data. This is specially true when we work with large databases because dtypes as `category` for example use less memory than string.\n",
    "\n",
    "When using the funcion `pd.read_csv()`, we can give to the argument `dtypes` a dictionary with column names as keys and dtype as value. We can either type this dictionary or use dict comprehension to generate a template and then edit it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2151d5-18af-4b18-90e2-c756f2abc24d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "{col : 'string' for col in fake_df.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7bc850-7926-470d-8148-197e0248875c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# copy / paste and edit:\n",
    "d = {'letter': 'category',\n",
    "     'fruit': 'category',\n",
    "     'value': 'float32',\n",
    "     'numbers_list': 'string',\n",
    "     'date': 'string'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287c96a7-a918-4fd4-8a34-12d4d7eae913",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df = pd.read_csv(\"data/fake.csv\", dtype=d)\n",
    "fake_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1271571-2125-41e5-b70b-080586b38dc4",
   "metadata": {},
   "source": [
    "**Note**: If a column is not in the dictionary provided to `pd.read_csv()`, Python will try to infer the dtype."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c4a277-7800-460a-ad40-9a361c5458ce",
   "metadata": {},
   "source": [
    "**>>>** Set the right dtypes for the survey DataFrame (df).\n",
    "\n",
    "- \"country\", \"population\", \"size\", \"pets\", \"sport\", \"colour\", \"show\", \"time\" will be 'string'.\n",
    "- \"pop_clean\", \"educ_years\", \"salary\", \"siblings\" can all be 'int32' to save up a little bit of memory.\n",
    "- \"age_group\", \"father_degree\", \"mother_degree\", \"gender\" will be 'category'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e69939-372c-4e14-a193-b18696438d97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d6c3eb-ff58-4da4-99f5-12c07a2fc071",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to delet\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d671d2-c0b9-4d73-b7f4-64e744583823",
   "metadata": {},
   "source": [
    "### Time format\n",
    "\n",
    "Our \"df\" and \"fake_df\" both contain dates. However if you take a look at it, they're only strings, not dates yet. Pandas can use \"datetime\" objects allowing us to plot and perform operations on them.\n",
    "\n",
    "In order to do so, we can use the function ``pd.to_datetime()`` which will convert our strings to the right format. Sometimes Pandas will be able to infer automatically the date format. But in this case the strings are not standards so we need to pass a *strftime* (string format time) to the parameter \"format\" to tell Python what's the format date.\n",
    "\n",
    "Each % following by a letter means Python is going to replace it with the elements it finds. The next letter that follows the \"%\" is code, the rest of it is just characters which will be erased when converting to the datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674139db-c83a-400e-abb6-6b69efa530ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.to_datetime(fake_df['date'], format='%Hh:%Mm:%Ss %d-%b-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff993a2-f00b-4a0a-ac31-15b504cc433d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Once we're happy with the result, let's create a new Series\n",
    "# that will contain the date in the right format\n",
    "fake_df['datetime'] = pd.to_datetime(fake_df['date'], format='%Hh:%Mm:%Ss %d-%b-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb025ab2-2fec-448a-96de-66bd76f75022",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can now perform operations on this Series\n",
    "fake_df['datetime'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebf5637-970d-4272-aeb5-6eaa1f5e1879",
   "metadata": {},
   "source": [
    "## The Series \"time\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32195bea-4c5b-40f4-96ba-19ad5e10d26f",
   "metadata": {},
   "source": [
    "**>>>** Create a new Series in our df named \"datetime\" with the function `pd.to_datetime()` and the right *strftime* that will store our dates with in datetime format.\n",
    "\n",
    "To better understand how a *strftime* is used, move the edit cursor inside the function's name, then press \"shift+tab\". It will open the \"doc string\" which contains a lot of useful informations. There's a link inside the \"format\" section, follow the link, it will take you to the pandas documentation (go to the bottom of the page).\n",
    "\n",
    "Then find the minimum value, the maximum value and the mean of the \"datetime\" Series we've just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46291f50-0aa4-4413-bdef-6ed6d48259cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df['time'][0]) # Checking what the first line looks like\n",
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ccf58c-e8d8-4ce6-a942-eecc4aaf15b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When you're done, replace the old Series with the new one here\n",
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d150ed3-bd81-44b2-bda8-954b84e2b1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the min:\n",
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c74e47a-67ae-4779-9021-d33e02238261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the max:\n",
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33729ba-e9c6-4be5-9dfe-dcfd9600321c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display the mean:\n",
    "# Code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e086a074-76db-4d20-892a-f1215f9e6092",
   "metadata": {},
   "source": [
    "**>>>** Drop the Series \"time\" from your df."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b49092-3b4d-422e-9b81-f148137a7fd0",
   "metadata": {},
   "source": [
    "**/!\\ WATCH OUT !** This time we're not replacing or creating a **Series** we're replacing the whole DataFrame !\n",
    "\n",
    "- You can get confused very easily. Luckily if you make a mistake, it's also very easy to go back and re-run the cells.\n",
    "- If you have several columns to drop, you can give to the method `.drop()` a list of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926eb390-6c33-4694-b4ac-3c0021ba30a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26f29a0-9c32-472f-8459-0fad19d5b462",
   "metadata": {},
   "source": [
    "## Plotting data\n",
    "\n",
    "Let's go back to our fake_df. You can plot a Series like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb61f2fe-2c90-46e5-8d50-1916d77c4e95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['value'].plot(); # Adding a semicolon removes useless legend\n",
    "# Note that line stops as soon as it encounters a missing value (NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c45fd3b-a278-4461-9de7-1c8fefb8d27d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can specify what graph you want with the 'kind' parameter.\n",
    "# Let's use a bar graph first.\n",
    "# Bar graphs are usually used to plot categorical data.\n",
    "# As we want to plot the value for each row of our fake_df, this would work.\n",
    "\n",
    "fake_df['value'].plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8fec7d-abd7-47a2-ba9b-2dd2e9e32da6",
   "metadata": {},
   "source": [
    "But the xticks are the index of our DataFrame. Let's plot some values as \"y\" and some categorical values as \"x\". In order to do this, you can use ``.plot()`` directly on a DataFrame, allowing you to manipulate multiple Series easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3050d33a-eee0-471c-8237-987faf10ecb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.plot(x='letter', y='value', kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d9a7c1-d225-405a-be9c-f60f15d98966",
   "metadata": {},
   "source": [
    "## The Series \"pop_clean\"\n",
    "\n",
    "It contains the number of inhabitants in several countries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd516fa-4445-4e16-af3e-55d600c9f9a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "**>>>** Plot both the Series 'pop_clean' and 'country' on the same graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f947f80-bd8e-4e1b-960f-0013e1e01103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db477883-c846-4418-b868-f01728a5bcfd",
   "metadata": {},
   "source": [
    "### Operations on numeric data\n",
    "\n",
    "The Series **'value'** in *fake_df* and **'pop_clean'** in *df* are both numerical data. Meaning you can apply many different statistical functions on them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aa559c-f705-4cf8-9044-a7507e02bbad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['value'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51097083-14fb-4d0a-b5f9-a43a347f52eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['value'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97435c2-3e68-4556-86d7-d15463bd155a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['value'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ad4ae9-2cbc-43d2-802d-ad9b0007ff00",
   "metadata": {},
   "source": [
    "**>>>** Have a look at basics statistics on the \"pop_clean\" data. You can use the function `.astype(int)` to convert the result to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646d00bc-4119-4799-a9c0-e4748cededa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0b2c6e-5220-42f5-b620-76351acc174c",
   "metadata": {},
   "source": [
    "### Displaying large float numbers\n",
    "\n",
    "When working with large float numbers, it might be useful to change the way Pandas display them. For example :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7149278-88b0-4ded-bfbd-784591bcd6ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We create a function that will add commas as thousands separator,\n",
    "# and then replace_them with an underscore,\n",
    "# also it only takes up to 2 digits now.\n",
    "def thousands_separator(x):\n",
    "    return '{:_.2f}'.format(x)\n",
    "pd.set_option('display.float_format', thousands_separator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393d1c70-4fe1-41d7-91b4-462c349a2fb9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plotting the data\n",
    "\n",
    "To get a better grasp at a Series, we can plot them using the method ``.plot()``. It works fine on numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27473c25-1c35-4ea5-862d-29917c20a36b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['value'].plot(); # Adding a semicolon removes useless legend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a45456-48e0-4778-95c0-4c5ddb39c375",
   "metadata": {},
   "source": [
    "But if we apply the same function on a categorical column, it will return an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c214dc31-d092-4646-93b7-74022480535e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Yields an error!\n",
    "#df['country'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d83d280-4015-4692-ad72-3a3845492635",
   "metadata": {},
   "source": [
    "### The method ``value_counts()``\n",
    "\n",
    "This method is very useful, it takes as input almost any Series and return a new Series which displays the number of occurrences for each elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a5d18a-5fcf-4546-b77a-a0321edf758a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['letter'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e5037c-2c60-45ad-a5c3-27d79559ae87",
   "metadata": {},
   "source": [
    "## The Series \"country\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cae2df-f2a5-4e76-b041-beaf19ff121f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['country']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7adca6f-3101-405f-b49a-05d5bdcef9ae",
   "metadata": {},
   "source": [
    "**>>>** Use the ``.value_counts()`` method and plot the \"country\" Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb0622c-0a33-44cf-8b76-3db072e1e46c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f5c55b-b7dd-458d-8d2e-37b9d6910d00",
   "metadata": {},
   "source": [
    "**>>>** This works, but it's not ideal. Check the [online documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html) and give better arguments to the parameters of the `.plot()` method in order to display a useful graph. You're probably going to use the parameter \"kind\", and maybe \"rot\" (rotation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63bfa99-5012-4fcb-96bc-bcfb5412889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eb6d04-dd16-4305-a2dd-88f735539863",
   "metadata": {},
   "source": [
    "## String manipulation\n",
    "\n",
    "As you can see some country names start with a capital letter, and some others are lower-case. Pandas provides many functions to work with strings. They are in a submodule called `.str`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae70196c-4f89-4140-b3de-6f06c8f706e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['letter'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e4e9ab-f272-401b-b74f-3f710b4fbab6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['letter'].str.replace(\"D\", \"The function can also be used!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d298cabe-f531-4092-b2c5-5596b403b031",
   "metadata": {},
   "source": [
    "## Fixing the strings in the Series \"country\" \n",
    "\n",
    "**>>>** Capitalize the strings inside the Series \"Country\". When it's done, replace the old Series with the new one and plot the data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1c49ad-3c75-44f4-8b3b-6442d98a40cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffde556-ecac-4fff-8b29-39a7631ff8b4",
   "metadata": {},
   "source": [
    "## The method `.sort_index()`\n",
    "\n",
    "We can apply the method `.sort_index()` on a Series to reorganise the index, which is useful to better visualize results or to plot data. It uses alphabetical order for strings, and ranking for numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b474c8-e8c0-4a0d-8b56-43cf166df16b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remember this Series of random letters?\n",
    "fake_df['letter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac87eb63-2201-43d1-8ebd-3118e9223df8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['letter'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a7669a-90db-4596-b290-d5f72480cf4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['letter'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09211c1-48e2-4bfd-9181-f0a4addc6ff2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['letter'].value_counts().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f566242a-2c92-44c2-81ca-fcede5777350",
   "metadata": {},
   "source": [
    "## The Series \"educ_years\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2022ca5-7f4c-496e-aacd-478f1ada8b80",
   "metadata": {
    "tags": []
   },
   "source": [
    "**>>>** Let's take a closer look at the \"educ_years\" Series :\n",
    "- Display basic statistics with `.describe()`.\n",
    "- Plot the \"educ_years\" Series using a \"bar\" graph.\n",
    "- Now plot it using a \"kde\" (Kernel Density Estimator) graph.\n",
    "- Use ``.value_counts()`` on the Series and plot the result.\n",
    "- Make sure your xticks are ascendant, using the using the method ``.sort_index()`` on your Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cce08c5-3acb-4e6c-a4a9-8eeac72f0a08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988b6ecc-3966-41c2-bee8-156e2aed4872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef562f4-2fd4-451d-aefa-49c67995c589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6e426d-16fd-4314-8b18-a05b05417cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ddf5ad-45d9-42b7-b211-6b4a27396189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48136f52-d367-443c-b8fc-b83ffbf254f7",
   "metadata": {},
   "source": [
    "## Selecting data in Pandas : ``.iloc[]`` and ``.loc[]`` methods\n",
    "\n",
    "The `.iloc[]` and ``.loc[]`` methods in Pandas are used for indexing and selecting data in DataFrames. They serve different purposes and work based on different indexing schemes:\n",
    "\n",
    "### The ``.iloc[]`` method (Integer Location)\n",
    "\n",
    "``.iloc[]`` is primarily used for selecting data by integer position, which means you specify row and column positions numerically :\n",
    "\n",
    "- It accepts integer-based indexing for both rows and columns.\n",
    "- The indexing is zero-based, similar to Python lists.\n",
    "- You can use integers, slices, lists, or boolean arrays to select data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35f01b8-a86c-4f05-a599-6c76a0695b39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.iloc[0]  # Select the first row\n",
    "# Note that it returns a Series, not a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50d759b-2e2b-41de-888a-ce173aec7865",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.iloc[2:5, 1:3]\n",
    "# Returns a DataFrame because they are several Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2b63cc-63f8-4005-b187-d4714da01e01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.iloc[[0, 3, 5], [1, 2]]  # Select specific rows and columns by integer positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20095383-60b7-4c17-9830-6487cacc3b2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select specific rows and columns with boolean indexing\n",
    "fake_df.iloc[[True, False, True, False, True, True, False, True, False, True, False], [False, True, True, False, False, True]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b93652-37a0-4b7c-8f6c-4f65ec8c417e",
   "metadata": {},
   "source": [
    "### The ``.loc[]`` method (Label Location)\n",
    "\n",
    "The method ``.iloc[]`` can sometimes be useful, but generally we use the ``.loc[]`` method which is very powerful. It allows us to select data by label or label-based conditions.\n",
    "\n",
    "- It accepts label-based indexing for both rows and columns.\n",
    "- Unlike most of the indexing in Python : the indexing is **inclusive on both ends** (i.e., slices include the specified labels).\n",
    "- You can use labels, slices, lists, or boolean arrays to select data.\n",
    "- You can filter using conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e9a9e0-87e2-4127-bce0-c16809e43279",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.loc[0:3, 'fruit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c11aa22-154e-481d-ba4c-2fb912fe9fcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.loc[1:2, ['fruit', 'datetime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16a0141-fe09-422d-ba37-3361e893c061",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Just like .iloc[], you can filter rows and columns using boolean indexing\n",
    "fake_df.loc[[True, False, True, False, True, True, False, True, False, True, False], [False, True, True, False, False, True]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ca1d22-e06a-4b77-a559-8e0cf247527c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pandas returns a boolean Series when you make comparison\n",
    "fake_df['value'] > 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b9da22-2c05-497b-b52d-dddf00b5de81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can use this boolean Series to filter your DataFrame using .loc[]\n",
    "fake_df.loc[fake_df['value'] > 500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f734988e-f337-4d40-a881-2f9ff3218c34",
   "metadata": {},
   "source": [
    "## The Series \"salary\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c615cf7d-a34c-4f62-b267-cbc6e3b3f104",
   "metadata": {},
   "source": [
    "**>>>** Let's have a look at the \"Salary\" Series.\n",
    "\n",
    "- Display basic statistics.\n",
    "- Plot it.\n",
    "- Choose a threshold , remove the outliers using ``.loc[]`` and compute the same stats.\n",
    "- Generate a new graph without the outliers.\n",
    "\n",
    "**TIP**: When using a hist graph, you can decide the numbers of \"columns\" using the \"bins\" parameter. Default is set to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e9cf84-7612-4848-acc1-d65a617d49e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d546fda9-4a5c-4227-b015-92592473e2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25e1fd1-f740-4fde-a4d1-f4953e3e0f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bad50b-4aa1-4cd6-baa8-9c7650d5151c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfab1d4-0a5e-472e-8d2b-ed464550d748",
   "metadata": {},
   "source": [
    "## Outliers : the thumb rule\n",
    "\n",
    "In statistics, an outlier is an observation or data point that significantly deviates from the majority of the other data points in a dataset. Outliers can be unusual values that are either much larger or much smaller than the typical values in the dataset. They are often referred to as \"extreme\" values.\n",
    "\n",
    "Sometimes, when you process a huge amont of data and you need to remove the outliers, you can use a statistician thumb rule : an outlier is a value that is above (or below) the distribution mean plus (or minus) three times the standard variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4b8334-0763-4d7c-bad2-7eedb4ea8fe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['value'] # There are 2 outliers there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8de02e-4d87-4619-800d-98ee0db5577c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['value'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92adc6ee-dff0-4e8d-99ab-2598ef447026",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['value'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b18929-c267-4312-ae33-2bb452134a0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# thumb rule for outliers : mean +/- 3 times the std\n",
    "# Upper bound :\n",
    "print(fake_df['value'].mean() + 3 * fake_df['value'].std())\n",
    "# Lower bound :\n",
    "print(fake_df['value'].mean() - 3 * fake_df['value'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf456063-59a4-4661-addb-d006b98e1e6c",
   "metadata": {},
   "source": [
    "However this \"thumb rule\" doesn't apply here as we don't have enough data. So let's just take the mean and add or remove the standard variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead48cf5-5f16-42ae-8206-8b58fd138935",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# our rule for outliers : mean +/- the std\n",
    "# Upper bound :\n",
    "print(fake_df['value'].mean() + fake_df['value'].std())\n",
    "# Lower bound :\n",
    "print(fake_df['value'].mean() - fake_df['value'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6901a32d-9f2f-4e33-9103-98f63a131e26",
   "metadata": {},
   "source": [
    "## The .between() method\n",
    "\n",
    "The ``.between()`` method allows us to create a boolean Series which returns ``True`` if the value is between the 2 arguments, and ``False`` if it's not the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2461f2-095a-42c0-b67d-09f0ce6243e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['value'].between(-22, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38867ca7-2f11-42b5-a6e6-f6a378e07f96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can then filter your entire DataFrame based on that condition\n",
    "fake_df.loc[fake_df['value'].between(-22, 1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e498f5-94b6-43ae-821e-d4d6ec71d00b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's apply our \"outliers policy\" on our dataframe:\n",
    "\n",
    "fake_df.loc[fake_df['value'].between(\n",
    "                            fake_df['value'].mean() - fake_df['value'].std(), # lower bound\n",
    "                            fake_df['value'].mean() + fake_df['value'].std() # upper bound\n",
    "                                     )]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d508c0-b6d1-4318-be6f-9af92724f3a7",
   "metadata": {},
   "source": [
    "Note that our missing values in the column \"value\" have also disappeared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23df1ea-6aef-4116-a4c6-3da6fe8b2763",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creating a subset of a DataFrame\n",
    "\n",
    "Let's store the result in a new DataFrame, which will be a **subset**, or a **view**, of our original DataFrame, just like when we slice an array with Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81006d1-753e-4ad0-91ea-4844cd1077b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_values_fake_df = fake_df.loc[fake_df['value'].between(\n",
    "                            fake_df['value'].mean() - fake_df['value'].std() # lower bound\n",
    "                          , fake_df['value'].mean() + fake_df['value'].std() # upper bound\n",
    "                                             )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd74400-a82a-4f00-96ca-f653130d6a75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_values_fake_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b56d59-6743-4ff0-99ff-bb8096bd7383",
   "metadata": {},
   "source": [
    "## Creating a subset of \"salary\" without outliers\n",
    "\n",
    "There are many ways to deal with outliers. One of the easiest way is just removing the rows that contain extreme values. However, we don't want to modify our original DataFrame.\n",
    "\n",
    "**>>>** Create a new DataFrame called \"salary_df\" which will not contain the rows where the salary values are over a thresold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef12060-2eb5-4ff4-a2c5-b9a8c4c496b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b46456a-0ff3-4e38-ac24-a72a9e775283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When you're happy with the result,\n",
    "# create in this cell a new dataframe called \"salary_df\"\n",
    "# which doesn't have any outlier\n",
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bf24fa-c37b-4cf6-99c6-0bef8f8755e5",
   "metadata": {},
   "source": [
    "# Group By and Aggregations\n",
    "\n",
    "## Group By\n",
    "\n",
    "\n",
    "In data science, a \"Groupby\" is an operation that involves splitting a dataset into groups based on one or more criteria. It is a way to break down data into smaller, manageable pieces for analysis.\n",
    "\n",
    "Once data are separated in different groups, we usually apply one or several functions on each different group.\n",
    "\n",
    "## Aggregations\n",
    "\n",
    "\n",
    "\"Aggregations\" refer to the process of applying a mathematical or statistical function to a set of data to obtain a single summary value. Aggregations typically involve operations like sum, mean, median, count, min, max, etc.\n",
    "\n",
    "Aggregations are used to summarize and condense data, providing insights into the overall characteristics of a dataset or specific groups created using groupby.\n",
    "\n",
    "## Exemples\n",
    "\n",
    "Let's imagine we have a library with several books classified with their genre. We can group them and apply the function `.sum()` to check how many books we have for each different categories.\n",
    "\n",
    "<img src=\"files/group_by-sum.jpg\" width=\"90%\" align=\"center\">\n",
    "\n",
    "But we could also apply the function `.mean()` to compute the average.\n",
    "\n",
    "<img src=\"files/group_by-avg.jpg\" width=\"100%\" align=\"center\">\n",
    "\n",
    "[Source](https://learnsql.com/blog/group-by-in-sql-explained/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57d003a-fce8-41e1-91f1-0ca6c1aa655d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Performing GROUP BY on our datasets\n",
    "\n",
    "### A simple Group By\n",
    "\n",
    "We can create groupby objets without applying a function, and save it for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176cb36e-806c-4e89-8799-d6e6ff970dc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_values_fake_df.groupby('letter') # Data have been grouped by Letter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b90b6cd-df41-443e-a1b0-a79862491d6d",
   "metadata": {},
   "source": [
    "### Simple functions\n",
    "\n",
    "#### ``.sum()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a09f50-e8c3-4478-96ee-f859ae5ef807",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If we remove numeric_only=True, Pandas yield an error,\n",
    "# because you can't apply this function on strings.\n",
    "clean_values_fake_df.groupby('letter').sum(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591edab5-d235-42cc-a378-6b420facfda1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### ``.count()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab19cf5d-7b2d-4b7e-9292-7fa95b265b6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's use a count()\n",
    "# here we don't need the parameter numeric_only=True\n",
    "# because count() can be applied on any object.\n",
    "clean_values_fake_df.groupby('letter').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c71a2a2-70b4-4c90-97b0-ccb2ff0aea55",
   "metadata": {},
   "source": [
    "#### ``.mean()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee6044c-c974-440f-a5b6-b703930cc35e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_values_fake_df.groupby('letter').mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29f97e1-0fb9-48c5-b204-eed4afa27549",
   "metadata": {
    "tags": []
   },
   "source": [
    "### The method ``.agg()``\n",
    "\n",
    "\n",
    "The .agg() method in Pandas is used to perform aggregation operations on a DataFrame or Series.\n",
    "\n",
    "We can specify one or more aggregation functions that we want to apply to the data. These functions can be built-in functions like ``sum()``, ``mean()``, ``min()``, ``max()``, or custom functions.\n",
    "\n",
    "It can take strings arguments, lists or even dictionaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f87852a-32fa-4190-ae09-525740b47e4b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### ``.agg()`` with one function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03a275a-efea-4772-abb0-fd5560fcff8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_values_fake_df.groupby('letter').agg('mean', numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602f146d-1001-455b-a169-501cf6f0597b",
   "metadata": {},
   "source": [
    "#### ``.agg()`` with several functions\n",
    "\n",
    "Here we took only the Series \"value\" from the grouped data, and apply three different functions to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae717d6f-ecd0-490d-a73d-ed5131ebeb05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_values_fake_df.groupby('letter')['value'].agg(['count', 'sum', 'mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084b6a0e-9a95-431d-8d4b-ae6530844d5b",
   "metadata": {},
   "source": [
    "#### ``.agg()`` with a dict of arguments\n",
    "\n",
    "Passing a dictionnary of arguments allows us to better control the behavior of the aggregation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52938c2b-b54e-41e4-a22e-1d6944b54f8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_values_fake_df.groupby('letter').agg({\n",
    "        'value' : ['mean','median', 'max', 'min'],\n",
    "        'fruit':  ['count']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddaf4cb-8d89-4196-8683-74e53abc911e",
   "metadata": {},
   "source": [
    "**>>>** Let's find out if we can learn more about the participants of this survey. Using the previous \"salary_df\" we've created :\n",
    "\n",
    "- Group by age and look at the max, the min, the count, and the average salary.\n",
    "- Plot the average of the last result to better visualise.\n",
    "- Group by gender and look at the max, the min, the count, and the average salary.\n",
    "- Plot the average of the last result to better visualise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3927e274-c620-4b8e-8b30-8574d9742204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca461abc-ec1e-4220-9c5e-8af01fcd3882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e4ec68-fd8a-4e6f-8a2d-e5a297d3a201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f752c9-f6d9-4607-8db2-b1144fc30682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c5bbb7-2806-4308-926c-b39cfd2b90db",
   "metadata": {},
   "source": [
    "## The `.map()` method\n",
    "\n",
    "The .map() method in Pandas is used to transform values in a Series based on a mapping or a provided function. It is a versatile and flexible way to apply custom transformations to the data. Here's how the .map() method works:\n",
    "\n",
    "\n",
    "- If you provide a dictionary, it maps existing values in the Series to new values.\n",
    "- If you provide a function, it applies the function to each element in the Series.\n",
    "\n",
    "**Output**: The result is a new Series with transformed values based on the mapping or function.\n",
    "\n",
    "Let's see some examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97719de-8aa9-48b6-9f70-28206de20c79",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Using a custom function with `.map()`\n",
    "\n",
    "Once we've created a function, `.map()` will apply the function on each element and returns a new Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24c3b5f-47aa-4662-899b-b04b1e9f48f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's define a function\n",
    "def adds_1000(number):\n",
    "    return number + 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a053d5b-230b-4ee9-bbae-de2e22cb99f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "adds_1000(123.53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5c9cfd-8588-4adc-a00a-c4f6239bc76b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['value'].map(adds_1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fc3dee-9d08-4067-b943-3b0935fc7e72",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Using a dictionary with `.map()`\n",
    "\n",
    "If we give a dictionary to `.map()`, it will map the different elements. If it finds the key, it will replace it with the corresponding value. Doing this is called \"mapping\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ace6f5d-0123-4f39-964d-91eccd0b041a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_mapping_dict = {'A': 'Z',\n",
    "                   'B': 'Y',\n",
    "                   'C': 'X',\n",
    "                   'D': 'W'}\n",
    "\n",
    "fake_df['letter'].map(my_mapping_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e17da6-9d0c-4c65-b6fc-55a61fcd514b",
   "metadata": {},
   "source": [
    "# The Series \"siblings\"\n",
    "\n",
    "There is an error in the statement of the question. Can you spot it?\n",
    "\n",
    ">How many siblings do you have, including yourself? Example: If you have 2 sisters and 1 brother, write 4.\n",
    ">Include half-siblings - or your step-mother or step-father's children-  if you grew up with them.\n",
    ">If you are an only child, enter 0.\n",
    "\n",
    "We'll need to correct the answers before using it. To do so, we'll use `.map()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06ec53b-a658-4683-9d61-1447ebd902b6",
   "metadata": {},
   "source": [
    "**>>>** Use `.map()` with a custom function to correct the \"Siblings\" Series.\n",
    "- If number of siblings is 0, set it to 1. Otherwise leave the current number.\n",
    "- When it's done replace the old Series with the new one.\n",
    "\n",
    "**TIP**: If you made a mistake you can re-run all the cells from the top to get your df as it was originally. You can do it with \"shift+enter\" or using the \"Run all above selected cells\" in the run menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4fd638-dda3-4424-9cc7-2ea4a4054905",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7aad59-2f64-4590-8125-972ddfa0cf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the old Series with the new one in this cell\n",
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408d1241-d51b-43c3-b5b5-e52cf52a3bc7",
   "metadata": {},
   "source": [
    "# The Series \"age_group\"\n",
    "\n",
    "**>>>** Plot the data using a bar graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b147af27-7b49-4c60-8107-4129b0f35288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cce191-83a5-4746-9a83-d3db6f5e9ba4",
   "metadata": {},
   "source": [
    "## The methods `.unique()` and `.nunique()`\n",
    "\n",
    "### `.unique()` \n",
    "\n",
    "- The `.unique()` method is used to return an array of all the unique values present in a Series. In other words, it removes duplicate values and provides a list of unique values.\n",
    "\n",
    "- It returns a new Series.\n",
    "\n",
    "### `.nunique()` \n",
    "\n",
    "- The `.nunique()` method is used to count the number of distinct (unique) values in a Series.\n",
    "\n",
    "- It returns the count of unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475bd916-71a2-4214-a513-1199faaa7cdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['letter'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843d05ea-0f13-433c-9290-0f91295c3f2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['letter'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f323d58-beba-44e2-9541-36674af1add1",
   "metadata": {},
   "source": [
    "## Creating a new Series : \"age_mean\"\n",
    "\n",
    "**>>>** Create a new Series called \"age_mean\" which will take the mean of each age group. There are several ways to do it:\n",
    "\n",
    "- Use a dictionary and `.map()` (quick and simple way).\n",
    "- Use `.unique()` to get all the unique strings, convert the elements in integer and compute the mean. You can either use a custom function or a comprehensive dictionary. To compute the mean, you can use `np.mean()` (more complicated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b624032f-72c6-4cee-97c8-907c2fb7cd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2efbfc-4ce3-4761-a40c-ac8b53f7722c",
   "metadata": {},
   "source": [
    "# Parents level of education\n",
    "\n",
    "These are ordinal values, but they are stored as strings. Let's make things right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047a97c8-fb00-41e9-88ac-b6a71b537f29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['father_degree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb2e52c-163c-4f32-b2b9-5ff7a1c62cf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['mother_degree']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1468a784-f575-434a-ae92-05a68bed4009",
   "metadata": {},
   "source": [
    "**>>>** Create new series with integer instead of strings.\n",
    "\n",
    "- The two new Series will be named \"father_el\" and \"mother_el\" (\"el\" = \"education level\").\n",
    "- Create a dictionary and use the `.map()` function to convert the strings to integer. The values will be :\n",
    "    - If the string is Do not wish to answer / can't answer\", replace it with `None`.\n",
    "    - If it is \"No diploma\" then 0.\n",
    "    - If it is \"French baccalaureate\" then 1,\n",
    "    - If it is \"Licence\" then 2,\n",
    "    - If it is \"Master or PhD\" then 3 \n",
    "    \n",
    "- At the end create a new Series named \"parents_el\" which will be the sum of \"father_el\" and \"mother_el\".\n",
    "\n",
    "- Once you've created \"father_el\" and \"mother_el\", convert them to an 'int' type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cd1a57-8e69-4770-b783-9d102256fd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7417227-bde6-43ba-b565-9963d2038ef9",
   "metadata": {},
   "source": [
    "# The Series \"size\"\n",
    "\n",
    "Let's say we want to know what is the average size of the people who took the survey. We first need to clean and convert those strings in integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a037d6e6-d5b1-4b75-b7ee-277507dfce88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['size']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caa491e-3f85-4bbb-a79c-65f0c22b0df2",
   "metadata": {},
   "source": [
    "**>>>** Write a custom function that clean the Series.\n",
    "\n",
    "- Apply it using `.map()`\n",
    "- Replace the old Series with the new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a254790-1b41-46ce-8b0b-f25e1d52961a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40db09d3-62b2-43d5-8e68-f11138e83e4e",
   "metadata": {},
   "source": [
    "# The Series \"gender\"\n",
    "\n",
    "**>>>** Create a new Series called \"gender_int\", and assign 1 if the gender is \"Woman\" and 0 if the gender is \"Man\". Convert this Series to 'int'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5a4f5e-c785-4880-88b5-9830f252c858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078df316-8b68-49b3-8f28-e120d26054d4",
   "metadata": {},
   "source": [
    "## The function `.str.split()`\n",
    "\n",
    "This function belongs to the submodule `.str`. It behaves almost the same way than the `.split()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff09118c-3892-4792-a2b7-1ab7a8d68bd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['numbers_list'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6176a415-734f-40a9-8ac0-b684db47da74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['numbers_list'].str.split()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcb60d1-7073-4b25-89d6-dd06f9ac66de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['numbers_list'].str.split('-')[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbb8bb2-592c-4f11-9fb4-b3bbe45bbcbe",
   "metadata": {},
   "source": [
    "# The Series \"pets\"\n",
    "\n",
    "This Series has an issue. Several data are stored in the same string. Let's separate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68505e2-e90d-4cca-b1c3-644bc411e2f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['pets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268bdbdd-b42f-49cd-8bdf-0d62da994f83",
   "metadata": {},
   "source": [
    "**>>>** To deal with this data, we'll need to: \n",
    "\n",
    "- Put all the strings in lower case.\n",
    "- Find the right separator.\n",
    "- Split our data in three different Series named \"pet1\", \"pet2\" and \"pet3\". In order to do this use the parameter \"expand\"\n",
    "\n",
    "**TIP** : You can give a list of Series to a Dataframe. For example:\n",
    "\n",
    "```Python\n",
    "fake_df[['letter', 'value']]\n",
    "```\n",
    "It might be useful to create new Series in a single line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b78687c-8880-4015-b4f6-cc296d1e8c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a1a5c0-78d4-4df6-a3f5-3a193239f634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to create the 3 Series \"pet1\", \"pet2\" and \"pet3\"\n",
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0c4873-7e31-4324-a296-c7f899959960",
   "metadata": {},
   "source": [
    "# Correlation\n",
    "\n",
    "Let's see if we can find any correlation in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988233fb-6213-4d94-a44a-1ba5f1411d82",
   "metadata": {},
   "source": [
    "## Prepare the dataset\n",
    "\n",
    "First let's create a view of our df with only the variables of interest such as:\n",
    "\n",
    "- 'pop_clean'\n",
    "- 'educ_years'\n",
    "- 'salary'\n",
    "- 'siblings'\n",
    "- 'size'\n",
    "- 'gender_int'\n",
    "- 'age_mean'\n",
    "- 'parents_el'\n",
    "\n",
    "### The method `.copy(deep=True)`\n",
    "\n",
    "When we slice our DataFrame, it creates a **view**, not a **copy**. However you can force Pandas to create a distinct copy using `.copy(deep=True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b2ed50-9e53-433b-a415-819a2605b35b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_fake_df = fake_df.copy(deep=True)\n",
    "new_fake_df['letter'] = \"Z\"\n",
    "new_fake_df['letter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a1c6bf-7e4f-4145-9d6e-c119a3df535e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Original df hasn't been modified\n",
    "fake_df['letter']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50191b98-a120-41e2-b3a6-bdf88ff3df66",
   "metadata": {},
   "source": [
    "**>>>** : Create a deep copy of our DataFrame named \"corr_df\" which contains only those columns of interest. Then apply the `.corr()` method on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05c0c6d-9747-4244-b650-774e19d179d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f088cc-3845-4c49-b848-0abb964dd910",
   "metadata": {},
   "source": [
    "## An other way to deal with outliers.\n",
    "\n",
    "We still have some outliers, especially inside the Series \"salary\". There are countless ways to remove them, let's use `np.where()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d80f540-768f-481b-87f5-d358add7c68c",
   "metadata": {},
   "source": [
    "### `np.where()`\n",
    "\n",
    "This function provides a way to perform conditional operations on NumPy arrays and Pandas Series. It allows you to generate a new array or a new Series based on a specified condition. The general syntax for `np.where()` is:\n",
    "\n",
    "```python\n",
    "np.where(condition, value_is_true, value_if_false)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94febc11-87fb-4e3b-825e-58bc030db963",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Exemple\n",
    "\n",
    "np.where(fake_df['value'] > 0, 10, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca5ef6d-ed5f-4c8d-aebf-9a50f9c24a6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Exemple\n",
    "\n",
    "# np.set_printoptions(precision=2, suppress=True) # useful to better visualize\n",
    "np.where(fake_df['value'] > 0, 10, fake_df['value'] / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b8d99e-18be-436e-a128-a14694efc498",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating or replacing a Series\n",
    "\n",
    "fake_df['new_value'] = np.where(fake_df['value'] > 0, 10, fake_df['value'] / 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e19d88-f494-41e4-ba6f-911ba855f885",
   "metadata": {},
   "source": [
    "**>>>** Replace the two outliers values we have in the \"salary\" Series with the median of that Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02c2131-3349-4b05-b63a-23ef968bf86d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0595256-d96e-43aa-bcc2-590f90e0530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's display the ne result\n",
    "corr_df.corr()#.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02bfda8-1208-48e6-ab5b-ca34dcb24e35",
   "metadata": {},
   "source": [
    "# Correlation visualisations\n",
    "\n",
    "When dealing with data, it's always a good thing to look at the data and not just numbers.\n",
    "\n",
    "## Anscombe's quartet\n",
    "\n",
    "Anscombe's quartet comprises four data sets that have nearly identical simple descriptive statistics, yet have very different distributions and appear very different when graphed. ([wikipedia](https://en.wikipedia.org/wiki/Anscombe%27s_quartet))\n",
    "\n",
    "\n",
    "<img src=\"files/anscombe.png\" width=\"70%\" align=\"center\">\n",
    "\n",
    "\n",
    "| Property                                                  | Value             | Accuracy                                |\n",
    "|-----------------------------------------------------------|-------------------|-----------------------------------------|\n",
    "| Mean of x:                                                | 9                 | exact                                   |\n",
    "| Sample variance of x:                                     | 11                | exact                                   |\n",
    "| Mean of y:                                                | 7.50              | to 2 decimal places                     |\n",
    "| Sample variance of y:                                     | 4.125             | ±0.003                                  |\n",
    "| Correlation between x and y:                              | 0.816             | to 3 decimal places                     |\n",
    "| Linear regression line:                                   | y = 3.00 + 0.500x | to 2 and 3 decimal places, respectively |\n",
    "| Coefficient of determination of the linear regression: R² | 0.67              | to 2 decimal places                     |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff68879-b7e3-494f-b111-388e6594d281",
   "metadata": {},
   "source": [
    "## Seaborn and heatmap\n",
    "\n",
    "Let's use Seaborn, a libray built on top of matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3813aec-bea8-49b5-a537-cc62e04874c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(corr_df.corr());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae9bff4-0e69-49f6-862c-3cd40e557c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's annot the heatmap and make it range from -1 to 1.\n",
    "sns.heatmap(corr_df.corr(), vmin=-1, vmax=1, annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff7f9d2-9956-48a4-9b13-286dc7eef621",
   "metadata": {
    "tags": []
   },
   "source": [
    "### The `sns.pairplot()` function\n",
    "\n",
    "This function is used to create a matrix of scatterplots, also known as a pairwise scatter plot matrix. It's a valuable tool for visualizing the relationships between multiple variables (columns or Series) in a DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09721d12-e110-4759-b971-934ad8ca32bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(corr_df, diag_kind='kde', kind='reg', plot_kws={'color': 'red'});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b597e64-3f16-4d57-8afe-dbfe359b39f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='parents_el',\n",
    "           y='salary',\n",
    "           data=corr_df,\n",
    "           fit_reg=True,\n",
    "           line_kws={'color': 'red'}\n",
    "          );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e3a1dd-5012-4d12-8b62-d81baebabd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='gender_int',\n",
    "           y='salary',\n",
    "           data=corr_df,\n",
    "           fit_reg=True,\n",
    "           line_kws={'color': 'red'}\n",
    "          );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f275f645-367e-4df6-9bc8-75d266842d97",
   "metadata": {},
   "source": [
    "# Advanced cleaning\n",
    "\n",
    "Population, colour and TV Show can be cleaned using more complicated techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0927e7ad-b50e-4c2b-b598-bc40d89fdfc7",
   "metadata": {},
   "source": [
    "## Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70675b1-a40c-4b21-977e-499742b133c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['population']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b380ae5d-3ec8-4249-ae1e-a3cb292a221a",
   "metadata": {
    "tags": []
   },
   "source": [
    "**>>>** Write a custom function and use `.map()` to clean the column population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de3cc8f-0b5a-42fe-800d-04c835d2e1c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d3495b-6749-45a7-b255-86e1fa5fea0c",
   "metadata": {},
   "source": [
    "# The Series \"sports\"\n",
    "\n",
    "**>>>** Use this [list](https://gist.githubusercontent.com/stefanoverna/371f009900bbe9ceec208f5dd1688737/raw/db7a90fa9e5dcb4ec22f4aef2774348fff7ccf69/gistfile1.txt) found on github, and the function `SequenceMatcher` from the `difflib` library to autocorrect sport names. Name your function \"correct\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f0392a-6194-4f1c-ab61-2f4aee0f9919",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca969022-e1f9-426c-bd12-9e96cd712593",
   "metadata": {},
   "source": [
    "# The Series \"colour\"\n",
    "\n",
    "**>>>** Find a list of colours on the internet and, just like the previous question, find a way to correct the data. You can reuse functions you've already written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d658961e-be49-47bb-a9f6-7f94de54e64c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['colour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1454c072-116e-411d-b049-89c8775740b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116a0bec-3a85-4a45-924b-d90737f18ef3",
   "metadata": {},
   "source": [
    "# TV Show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd4342e-f267-4651-8b5c-3cb46882ffee",
   "metadata": {},
   "source": [
    "### Scrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0347b1-80a9-424e-83d3-e90b9a7d5245",
   "metadata": {},
   "source": [
    "**>>>** Use scrapping to create a list of TV Show. And then correct the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc214249-e2f3-4dfa-b86c-7de7bfe617a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
