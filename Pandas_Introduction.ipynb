{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f58b7dcc-0aa8-4dca-8ec0-c4cb3db1312b",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "# Introduction to Pandas\n",
    "\n",
    "**Pandas** is a python library that has been created by **Wes McKinney** in 2007 on top of the **Numpy** library, and had become open sourced by the end of 2009. It is widely used in data science, machine learning and data analysis tasks. The name is derived from the term **\"PANel DAta\"** (tabular data), an econometrics term for data sets that include observations over multiple time periods for the same individuals. ([wikipedia](https://en.wikipedia.org/wiki/Pandas_(software)))\n",
    "\n",
    "**Pandas** works well together with other librairies such as **Matplotlib / Seaborn** and, of course, **Numpy**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dc562f-6c3f-4990-876d-5a7ed2eb0292",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"files/pandas_numpy_matplotlib_seaborn.png\" width=\"100%\" align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f9db81-31fe-4489-a401-1ab5e94f2e8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd # We'll use pd as the alias\n",
    "import numpy as np # and np as alias for numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a3057a-0a39-47a0-8607-fb1ff9f92091",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "# Series\n",
    "\n",
    "## Definition\n",
    "\n",
    "In Pandas, the equivalent of a 1-D NumPy array is called a \"Series,\" often referred to as a \"column.\" This object is very similar to a NumPy array, as it is constructed directly on top of NumPy arrays. This is why they share a number of characteristics. Indeed, like a NumPy array, a Series:\n",
    "\n",
    "- Can be empty or store **values**.\n",
    "- Has a **dtype** (*data type*) - but handles cases where the data in the Series are of different types better.\n",
    "\n",
    "However, Series differ from NumPy arrays since they have something new:\n",
    "\n",
    "- An **index**, which associates a value, often unique, with each entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21b1933-6634-44cc-8b1b-e797f5951dd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a Series from a list:\n",
    "s = pd.Series([87, 23, 12, 43, 52, 61])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ac7d67-01ac-40c0-9717-45b65ca34dd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To access an element, we can use Numpy syntax.\n",
    "s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a3267d-b57b-4036-b607-7f14d8d51f86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaea15c6-7063-4f54-a896-d928ed8f7d19",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Index and Series\n",
    "\n",
    "We can let Pandas decide, as in the previous example, or specify one using the following syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043f5c9c-dd78-424a-8e2f-d5e9e10a5e05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using a list for values and a list for index\n",
    "s = pd.Series([87, 23, 12, 43, 52, 61], index=[100, 102, 104, 106, 108, 110])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f501db-6f2f-4e28-ac99-6f372efc7e59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# or we can provide a dictionary, index is the key, value is value.\n",
    "s = pd.Series({100: 87, 102: 23, 104: 12, 106: 43, 108: 52, 110: 61})\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7dd9ef-b529-4f33-a7e7-fa515da9dae8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Accessing an element with the new index\n",
    "s[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561fe285-adb5-48d8-aa7b-a84892bd83d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s[110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1013b7bd-e219-4c11-9030-fa67e502cbd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can also set strings as index\n",
    "# And index doesn't have to be unique.\n",
    "s = pd.Series([87, 23, 12, 43, 52, 61], index=['Group 1', 'Group 2', 'Group 2', 'Group 2', 'Group 1', 'Group 3'])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22df98fd-fe68-4f1b-a70e-523501c168df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Accessing one or several elements using the new index\n",
    "s['Group 1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d97b0cd-5097-4b42-8067-e936a78c5e76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s['Group 2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55761509-6ba8-4909-bf4e-1a37d988dcbc",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "# DataFrame\n",
    "\n",
    "A *DataFrame* is a two-dimensional and easily manipulable data structure used to store and manipulate data in Python through Pandas. It is a **collection of Series** (an organised set of Series).\n",
    "\n",
    "Some key characteristics of a Pandas DataFrame:\n",
    "\n",
    "- **Bidimensional**: A DataFrame is often compared to a spreadsheet or an SQL table because it organizes data into rows and columns.\n",
    "\n",
    "- **Resizable**: You can add or remove rows and columns from a DataFrame.\n",
    "\n",
    "- **Named axes**: Rows and columns have labels (names).\n",
    "\n",
    "- **Operations**: DataFrames support a wide range of operations on data, including filtering, grouping, aggregation, pivoting, merging, joining, and much more.\n",
    "\n",
    "- **And many more... !** : handling missing data, export in various formats..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d2a22d-f970-4c7a-8570-8468ddd2d4b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"files/series-and-dataframe.png\" width=\"50%\" align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a65d70-a7fa-4dcf-a04b-eedf1b0bf33c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s1 = pd.Series([87, 23, 12, 43, 52, 61])\n",
    "s2 = pd.Series([100, 52, 35, 71, 62, 89])\n",
    "s3 = pd.Series(['m', 'f', 'm', 'm', 'f', 'f'])\n",
    "\n",
    "# There are multiple ways to create a dataframe from Series.\n",
    "# Let's go with a dictionary. Keys are column names and values are... values!\n",
    "\n",
    "df = pd.DataFrame({'age': s1, 'weight': s2, 'sex': s3})\n",
    "df # In Jupyter the display of a Dataframe is different from a Series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d27b4f-7e33-4239-8f4b-0125866b12dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"files/pandas_dataframe_schema.png\" width=\"100%\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2570caad-4caa-4098-8204-3f580b889c60",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Creating a DataFrame\n",
    "\n",
    "Pandas can create DataFrames from many differents file formats including :\n",
    "\n",
    "- CSV (comma separated value)\n",
    "- Excel (XLS and XLSX)\n",
    "- JSON (Java Script Object Notation)\n",
    "- HTML (Tables)\n",
    "- SQL (Databases)\n",
    "- Parquet\n",
    "- HDF5 (Hierarchical Data Format)\n",
    "- Feather\n",
    "- Stata\n",
    "- SAS\n",
    "- Google BigQuery\n",
    "- Clipboard\n",
    "- Python Dictionnaries\n",
    "- URLs (HTTP, FTP, etc.)\n",
    "- ... And many more"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebbc4a0-9f29-425d-a4ca-34f64cb96687",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Fake dataset\n",
    "\n",
    "Let's create a DataFrame from a CSV file stored inside the \"data\" folder and named \"fake.csv\". We'll use this fake dataset later to demonstrate some of the Pandas functions. Let's store it in a variable named : **\"fake_df\"**.\n",
    "\n",
    "**Note**: Here we're using a naming convention named **\"suffix Hungarian notation\"**, meaning the type of the object is included at the end of its name. And, of course, \"df\" is short for \"DataFrame\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b012afd5-eaa6-4694-a99a-b3586d7d6e26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df = pd.read_csv(\"data/fake.csv\")\n",
    "\n",
    "fake_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fe3ff0-c201-4c40-b53e-fede9073649d",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "If you run the cell above, you can tell right away that \"fake_df\" is a **DataFrame**: columns names and indices are in bold-style. And if you mouse over the DataFrame, rows are highlighted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680c7557-5eb3-4283-b820-7d7eb1f7adf4",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "# The Countries dataset\n",
    "\n",
    "## Presentation\n",
    "\n",
    "During this tutorial, we will use a well-known dataset that consists of a single file named \"countries.csv\" and contains a large number of different statistics about countries.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "We will use this file to examine if there is a correlation between four variables: population density (expressed in km²), GDP per capita ($), and birth and death rates ; at two different levels of analysis: at the country level and at the level of the region to which each country belongs.\n",
    "\n",
    "We will also examine whether the duration of their membership in the UN, if they are members, influences our variables to be explained.\n",
    "\n",
    "But before reaching this result, we will need to understand and clean up this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afa9593-f9bc-4a90-9a35-2b84d79524b9",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Reading a CSV file : \"countries.csv\"\n",
    "\n",
    "**>>>** Use the ``pd.read_csv()`` function to read the CSV file named \"countries.csv\" which is located inside the \"data\" folder. Store the result in a new DataFrame named \"df\".\n",
    "\n",
    "If you try to read a CSV file and Pandas returns an error, open the file with jupyter lab or a text editor (VS Code, Notepad++ etc.) and examine it to find the source of the error. The most common errors when reading a csv file are:\n",
    "\n",
    "- The **filepath** was not properly given to the function. The easiest way is to move the file you want to read in the same directory than your notebook file (or in a subfolder named \"data\").\n",
    "\n",
    "- A wrong **field separator**, by default Pandas assumes that it is the \",\" character. In this case specify the separator (= delimiter) with the argument \"sep\".\n",
    "\n",
    "- A bad **\"quotechar\"**, a character used to denote the start and end of a quoted item. Quoted items can include the delimiter and it will be ignored. In this case specify it with the \"quotechar\" argument.\n",
    "\n",
    "- The presence of **extra lines** at the beginning or at the end of the file. In this case use the \"skiprows\" or \"skipfooter\" arguments to ignore these lines.\n",
    "\n",
    "- Bad file **encoding**. The \"utf-8\" standard is the most common, but sometimes the files are in other formats like \"cp1252\" for example. In this case specify the encoding with the \"encoding\" argument. Hint: with the \"countries.csv\" file, the encoding is already 'utf-8'. \n",
    "\n",
    "**NOTE**: Do **NOT** open the file with the sofware \"Excel\", it may corrupt your file and make it unreadable, even if you don't save the modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f91dd39-4729-4510-8fd4-22bd2bcafcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4894468-6e20-48bd-a368-e07ee1e8eb3e",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "# First things to do\n",
    "\n",
    "## The `.shape` property\n",
    "\n",
    "We now have two DataFrames \"fake_df\" and \"df\". Let's take a look at our they're shaped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8952bb-2e50-461a-8f0d-a2407415534d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc778ab-4b9c-47c1-9e23-6e60c9577ee2",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**>>>** What shape is our df? What does it mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2375ac7-975b-4392-86bf-dec8900ed68a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5875ea1-231b-4f84-8b7b-ead0e304cc50",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## The ``.head()`` function\n",
    "\n",
    "It returns the first n rows, default is set to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6765fb02-2c49-4b7b-96b2-91c6ae7b1cb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a84850-46ca-41ad-8306-bac3c4829f8d",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**>>>** Use the ``.head()`` function to display the first 2 lines of our df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7116b0b-f256-4ed2-9f77-018f6cf13717",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401c26b4-713d-4a7d-95fa-1f0e8b946c1a",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## The `.columns` property\n",
    "\n",
    "It stores the names of our different columns. It is also the index of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9417547b-1377-4feb-8d45-a9a43881d72a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaf55d0-4488-414d-9196-98410dc8f17d",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**>>>** What are the columns of our DataFrame? Use a ``for`` loop to print each column name on a different line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120bb727-0a58-4f3d-a0f8-5d8111daa4b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbf9659-ddd8-4a07-99b3-51915c97f2c3",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## The `.index` property\n",
    "\n",
    "It stores the names of the rows (the index)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2fe2b7-507a-421a-a0ee-96af8dd9c3b2",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**>>>** What does the index of df look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434b439f-f3fa-4652-8407-54642c813f79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7103be-d382-42fd-b274-b0d418ed0510",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## The `.dtypes` property\n",
    "\n",
    "The word `dtypes` stand for \"data types\", it stores the types of our different columns. The type \"object\" is often a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe080a4-de3a-424c-9073-1058ea906151",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7539d74a-cc25-4d1c-a226-630cbf221aa6",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**>>>** What are the dtypes of our df?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09233a4-27b2-4315-837a-8ab0c9e5bfcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089403d3-e5c5-4f23-ac85-1e445cf45c3a",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Missing values : the `.isna()` method\n",
    "\n",
    "When you're given a new dataset, it is quite important to check if they are missing values. You can use the ``.isna()`` method, it returns a new DataFrame which has the same size than the original df, but the values are ``True`` if the value is missing and ``False`` if a value exists.\n",
    "\n",
    "That's one of the main strength of python : the outputs of many Pandas functions are also Pandas objects, meaning you can work on your data or your results using the same functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d63f96-8ee1-4257-bd7c-037d7ecc1a45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f085129f-2cc0-4e77-9bff-c3d1c1a3e3d4",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**>>>** Use ``.isna()`` on your DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16da66f-16e2-42ca-ab84-1817f19d6eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eeb562a-8e81-41d5-ba27-16f317e69d89",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Apply a function to a DataFrame : ``isna().sum()``\n",
    "\n",
    "The ``.sum()`` method performs a sum on an entire DataFrame. When performing sums, boolean values are treated as 1 if they're ``True`` and 0 if they're ``False``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaf90c2-551b-4179-99c2-24a5c33efe96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edea25a-e192-4601-9b7d-2330709c1dea",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**>>>** How many missing values in our DataFrame ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9b8df2-a36e-4e29-bea0-1970528a7c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85eccab-2620-4866-b255-4ac11cc4d59c",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**>>>** Slice the column \"Country\" from your DataFrame and display the corresponding Series. **Hint**: you can use the tab key for autocompletion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d08193a-3eeb-4115-b30c-c48ba89887d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efec20ba-9c90-4cc1-9f84-910ed3767572",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Creating or replacing Series\n",
    "\n",
    "Just like a dictionnary, to create or replace a Series you just have to assign it a value  or an object (list, dict, integer, almost any objects...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9525759-4c0d-48fa-acfa-a0b23131b144",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['one'] = 1\n",
    "fake_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e175db06-f1f6-4d4d-b5b8-9ec227d68687",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['one'] = 999\n",
    "fake_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5ec72a-d3db-4149-835c-d835a087ccd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df[['one', 'two']] = 1\n",
    "fake_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9778e2da-4d75-4ec1-8d75-1e872b63c2ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df[['one', 'two']] = 1, 2 # An implicit tuple\n",
    "fake_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67319b7e-ba24-4a02-b411-6ad5259198c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['three'] = fake_df['one'] + fake_df['two']\n",
    "fake_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f010a02-fbe0-496d-a763-ce22d1b7ee72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['count'] = [el for el in range(fake_df.shape[0])]\n",
    "fake_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23040353-8deb-4fe8-b8fe-e2e08b2677cb",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Dropping a Series\n",
    "\n",
    "There are several ways to \"drop\" (erase / remove / delete) a Series from your DataFrame, one of the easiest is just:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60751b9e-d3a5-4e1d-9a7b-595844fe3173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.drop(columns='one') # This function is not \"in place\" which means we haven't modified \"fake_df\" yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4608925c-518b-4335-9910-40933ed2bff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we're happy with the result\n",
    "# We can replace the old df with the new one\n",
    "fake_df = fake_df.drop(columns='one')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb0f2fd-06b8-4754-9b77-817763ed724c",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**/!\\ WATCH OUT !** This time we're not replacing or creating a **Series** we're replacing the whole DataFrame!\n",
    "\n",
    "One can get confused very easily. Luckily if you make a mistake, it's also very easy to go back and re-run the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc509bcc-4ace-43f1-a8b9-70da712de17d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can drop several columns by passing a list.\n",
    "fake_df.drop(columns=['two', 'three', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17afb14c-e8e5-4679-9751-db6ac515bf7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If we're happy with the result\n",
    "# We can replace the old df with the new one\n",
    "fake_df = fake_df.drop(columns=['two', 'three', 'count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bec7a2c-6700-44cd-9e68-c0e20da92616",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "# Dealing with data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3093926c-7015-498b-8d4b-ac076fe75223",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Setting the right data types\n",
    "\n",
    "Now that we know what is a DataFrame and a Series, and before we start doing something else, it's important that our Series are converted in the right type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc7ceb1-c9b9-43ac-941a-5e49e1802ab0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc597c7-c520-4d2d-8267-9532589f8c8b",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Conversion with `.astype()`\n",
    "\n",
    "There are many different types of dtype. Some of them use standard Python format, some are specific to Pandas and others are common to several other languages (PyArrow).\n",
    "\n",
    "Here let's use either:\n",
    "\n",
    "- `'string'` (which is a Pandas type)\n",
    "- `'category'` (also pandas type)\n",
    "- `int` (python type)\n",
    "- `float` (python type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63de3106-fb53-4c58-8bbe-e21c3dc5df04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# One conversion\n",
    "fake_df['letter'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2da2ed-076f-400f-81e7-fdac83d9d871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Several conversions\n",
    "fake_df[['fruit', 'letter']].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e62766-f253-4362-9e0c-586f65994450",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replacing old Series with new ones\n",
    "fake_df[['fruit', 'letter']] = fake_df[['fruit', 'letter']].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35f1d0a-a457-4241-b385-4bfa8ed1de2c",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Decimal Numbers: Dot or Comma?\n",
    "\n",
    "Some conventions use a dot to separate the decimals in a number, while others use a comma. You can specify the convention to Pandas during import by providing either ```'.'``` or ```','``` to the \"decimal\" parameter of the ```pd.read_csv()``` function. This allows Pandas to automatically infer the correct type based on the specified decimal separator.\n",
    "\n",
    "**>>>** Reimport our df with the \"decimal\" parameter and the right argument and take a look at the dtypes. Don't forget to also give to the function the correct arguments to the parameters sep, skiprows and so on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094de256-7aa2-44c7-bc64-36f15e2633b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba88b606-632a-4d7e-a484-cbad6315be23",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Conversion with a new import\n",
    "\n",
    "The best practice is probably to set the datatypes when importing the data. This is specially true when we work with large databases because dtypes as `category` for example use less memory than string.\n",
    "\n",
    "When using the function `pd.read_csv()`, we can give to the argument `dtypes` a dictionary with column names as keys and dtype as value. We can either type this dictionary or use dict comprehension to generate a template and then edit it.\n",
    "\n",
    "- You can also use the `usecols` parameter to tell Pandas to load only certain columns. Here, load only the columns of interest which are the columns :\n",
    "    - 'Country'\n",
    "    - 'Region'\n",
    "    - 'Population'\n",
    "    - 'Area (sq. mi.)'\n",
    "    - 'Pop. Density (per sq. mi.)'\n",
    "    - 'GDP ($ per capita)'\n",
    "    - 'Birthrate'\n",
    "    - 'Deathrate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2151d5-18af-4b18-90e2-c756f2abc24d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "{col : 'string' for col in fake_df.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7bc850-7926-470d-8148-197e0248875c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# copy / paste and edit:\n",
    "d = {'letter': 'category',\n",
    "     'fruit': 'category',\n",
    "     'value': 'float32',\n",
    "     'numbers_list': 'string',\n",
    "     'date': 'string'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287c96a7-a918-4fd4-8a34-12d4d7eae913",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df = pd.read_csv(\"data/fake.csv\", dtype=d)\n",
    "fake_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1271571-2125-41e5-b70b-080586b38dc4",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**Note**: If a column is not in the dictionary provided to `pd.read_csv()`, Python will try to infer the dtype."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c4a277-7800-460a-ad40-9a361c5458ce",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**>>>** Set the right dtypes for df by giving to the parameter \"dtype\" of the function ```pd.read_csv()``` a dictionary. (And don't forget to use also the \"decimal\" parameter). Use the ```usecols``` parameter to select only the columns of interest.\n",
    "\n",
    "- \"Country\" will be 'string'.\n",
    "- \"Region\" will be 'category'.\n",
    "- \"Population\" and \"Area (sq. mi.)\" will be 'int64' (or 'int32' if you want to save up a little bit of memory).\n",
    "- Everything else is 'float32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e69939-372c-4e14-a193-b18696438d97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1242218a-1cad-4c0c-b127-5f8fb66a00ef",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Rename the 'Area (sq. mi.)' and 'Pop. Density (per sq. mi.)' Series\n",
    "\n",
    "There is an error in the dataset; it should actually be in km², not square miles.\n",
    "\n",
    "**>>>** Rename the Series with the correct unit: 'Area (km²)' and 'Pop. Density (per km²)'. Use the function ```.rename()``` et pass it a dictionary as input, key being the old name and the value the new name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb474a8-3ff0-41bf-a3bd-a11610658840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26f29a0-9c32-472f-8459-0fad19d5b462",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Plotting data\n",
    "\n",
    "Let's go back to our fake_df. You can plot a Series like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb61f2fe-2c90-46e5-8d50-1916d77c4e95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['value'].plot(); # Adding a semicolon removes useless legend\n",
    "# Note that line stops as soon as it encounters a missing value (NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c45fd3b-a278-4461-9de7-1c8fefb8d27d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can specify what graph you want with the 'kind' parameter.\n",
    "# Let's use a bar graph first.\n",
    "# Bar graphs are usually used to plot categorical data.\n",
    "# As we want to plot the value for each row of our fake_df, this would work.\n",
    "\n",
    "fake_df['value'].plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8fec7d-abd7-47a2-ba9b-2dd2e9e32da6",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "But the xticks are the index of our DataFrame. Let's plot some values as \"y\" and some categorical values as \"x\". In order to do this, you can use ``.plot()`` directly on a DataFrame, allowing you to manipulate multiple Series easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3050d33a-eee0-471c-8237-987faf10ecb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.plot(x='letter', y='value', kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d9a7c1-d225-405a-be9c-f60f15d98966",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## The Series \"Population\"\n",
    "\n",
    "**>>>** Plot both the Series 'Country' and 'Population' on the same graph. Use only the first 10 rows of the dataframe to limit the number of information. In order to do so you can slice the df : ```df[:10]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f947f80-bd8e-4e1b-960f-0013e1e01103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db477883-c846-4418-b868-f01728a5bcfd",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Operations on numeric data\n",
    "\n",
    "The Series **'value'** in *fake_df* and **'Population'** in *df* are both numerical data. Meaning you can apply many different statistical functions on them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aa559c-f705-4cf8-9044-a7507e02bbad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['value'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51097083-14fb-4d0a-b5f9-a43a347f52eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['value'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97435c2-3e68-4556-86d7-d15463bd155a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['value'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ad4ae9-2cbc-43d2-802d-ad9b0007ff00",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**>>>** Have a look at basics statistics on the \"Population\" data. You can use the function `.astype(int)` to convert the result to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646d00bc-4119-4799-a9c0-e4748cededa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48136f52-d367-443c-b8fc-b83ffbf254f7",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Selecting data in Pandas : ``.iloc[]`` and ``.loc[]`` methods\n",
    "\n",
    "The `.iloc[]` and ``.loc[]`` methods in Pandas are used for indexing and selecting data in DataFrames. They serve different purposes and work based on different indexing schemes:\n",
    "\n",
    "### The ``.iloc[]`` method (Integer Location)\n",
    "\n",
    "``.iloc[]`` is primarily used for selecting data by integer position, which means you specify row and column positions numerically :\n",
    "\n",
    "- It accepts integer-based indexing for both rows and columns.\n",
    "- The indexing is zero-based, similar to Python lists.\n",
    "- You can use integers, slices, lists, or boolean arrays to select data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35f01b8-a86c-4f05-a599-6c76a0695b39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.iloc[0]  # Select the first row\n",
    "# Note that it returns a Series, not a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50d759b-2e2b-41de-888a-ce173aec7865",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.iloc[2:5, 1:3]\n",
    "# Returns a DataFrame because they are several Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2b63cc-63f8-4005-b187-d4714da01e01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.iloc[[0, 3, 5], [1, 2]]  # Select specific rows and columns by integer positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20095383-60b7-4c17-9830-6487cacc3b2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select specific rows and columns with boolean indexing\n",
    "fake_df.iloc[[True, False, True, False, True, True, False, True, False, True, False], [False, True, True, False, True]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b93652-37a0-4b7c-8f6c-4f65ec8c417e",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### The ``.loc[]`` method (Label Location)\n",
    "\n",
    "The method ``.iloc[]`` can sometimes be useful, but generally we use the ``.loc[]`` method which is very powerful. It allows us to select data by label or label-based conditions.\n",
    "\n",
    "- It accepts label-based indexing for both rows and columns.\n",
    "- Unlike most of the indexing in Python : the indexing is **inclusive on both ends** (i.e., slices include the specified labels).\n",
    "- You can use labels, slices, lists, or boolean arrays to select data.\n",
    "- You can filter using conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e9a9e0-87e2-4127-bce0-c16809e43279",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.loc[0:3, 'fruit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c11aa22-154e-481d-ba4c-2fb912fe9fcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.loc[1:2, ['fruit', 'date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16a0141-fe09-422d-ba37-3361e893c061",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Just like .iloc[], you can filter rows and columns using boolean indexing\n",
    "fake_df.loc[[True, False, True, False, True, True, False, True, False, True, False], [False, True, True, False, True]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ca1d22-e06a-4b77-a559-8e0cf247527c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pandas returns a boolean Series when you make comparison\n",
    "fake_df['value'] > 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b9da22-2c05-497b-b52d-dddf00b5de81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can use this boolean Series to filter your DataFrame using .loc[]\n",
    "fake_df.loc[fake_df['value'] > 500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c615cf7d-a34c-4f62-b267-cbc6e3b3f104",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Population Filtering\n",
    "\n",
    "**>>>** Use ```.loc[]``` and ```.plot()``` in order to:\n",
    "\n",
    "- Display a Series with the name of the countries with a population greater than 60 million.\n",
    "- Then generate a new graph with the name of the country (x) and their population (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25e1fd1-f740-4fde-a4d1-f4953e3e0f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bad50b-4aa1-4cd6-baa8-9c7650d5151c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12313758-eb42-4a06-a7f8-a20b45aeebe7",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "# Using ```.loc[]``` with Multiple Conditions\n",
    "\n",
    "It is possible filter with multiple conditions within a ```.loc[]```. In that case, we need to use the element-wise operators ```&``` and ```|``` instead of ```and``` and ```or``` to compare element by element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bc472c-5810-4cdb-8671-3213525b86a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# yields an error !\n",
    "#fake_df.loc[(fake_df['letter'] == 'D') and (fake_df['value'] > 500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ade0ef-d4d7-4ebe-84ed-38e8327059f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# works with the element-wise operator '&'\n",
    "fake_df.loc[(fake_df['letter'] == 'D') & (fake_df['value'] > 500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a32112d-1a0d-4c73-9b1e-e2f73e5768e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yields an error !\n",
    "#fake_df.loc[(fake_df['letter'] == 'D') or (fake_df['value'] > 500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e118448d-31f0-4715-9705-4ce0ad542b7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# works with the element-wise operator '|'\n",
    "fake_df.loc[(fake_df['letter'] == 'D') | (fake_df['value'] > 500)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8584aa-fb3e-457f-8bef-d69ad6b448cd",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "***>>>*** Use a ```.loc[]``` and display the countries that a population higher than 100 millions and a GDP per capita higer than $25 000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dc5b54-6456-4175-a45b-eeaba189b6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393d1c70-4fe1-41d7-91b4-462c349a2fb9",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Plotting categorical data\n",
    "\n",
    "If we try to plot a non-numeric Series, we get an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c214dc31-d092-4646-93b7-74022480535e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Yields an error!\n",
    "#df['Region'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d83d280-4015-4692-ad72-3a3845492635",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### The method ``value_counts()``\n",
    "\n",
    "This method is very useful, it takes as input almost any Series and return a new Series which displays the number of occurrences for each elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a5d18a-5fcf-4546-b77a-a0321edf758a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['letter'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e5037c-2c60-45ad-a5c3-27d79559ae87",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## The Series \"region\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cae2df-f2a5-4e76-b041-beaf19ff121f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Region']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7adca6f-3101-405f-b49a-05d5bdcef9ae",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**>>>** Use the ``.value_counts()`` method to display the list of different regions and their respective occurrences.\n",
    "\n",
    "**>>>** Then generate a graph indicating the frequency of each region using the ``.plot()`` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb0622c-0a33-44cf-8b76-3db072e1e46c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fe2f25-0209-410f-b7f6-3f6e40a926a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f5c55b-b7dd-458d-8d2e-37b9d6910d00",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**>>>** This works, but it's not ideal. Check the [online documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html) and give better arguments to the parameters of the `.plot()` method in order to display a useful graph. You're probably going to use the parameter \"kind\", and maybe \"rot\" (rotation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63bfa99-5012-4fcb-96bc-bcfb5412889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f840b8-062f-48b7-ab1e-95226f31eb2f",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## The methods `.unique()` and `.nunique()`\n",
    "\n",
    "- `.unique()` \n",
    "\n",
    "The `.unique()` method is used to return an array of all the unique values present in a Series. In other words, it removes duplicate values and provides a list of unique values.\n",
    "\n",
    "- `.nunique()` \n",
    "\n",
    "The `.nunique()` method is used to count the number of distinct (unique) values in a Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064032cc-61bf-4043-b0aa-ee90d61d46bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['letter'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed42e7e9-a481-4929-8a13-638abecc5f4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['letter'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dbbb16-5642-40c8-849a-8c157d9135ee",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### How many unique values in \"Region\"?\n",
    "\n",
    "**>>>** Use ```unique()``` and ```.nunique()``` to display unique values and the nmber of uniques values in \"Region\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19da0011-7b94-4f36-ab30-5db3fa01048b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755d5555-ff31-47a3-b6e5-4a977792d605",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eb6d04-dd16-4305-a2dd-88f735539863",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## String Manipulation\n",
    "\n",
    "As you can see, the names of the regions appear to have a lot of unnecessary spaces. Pandas provides many functions for working with strings. These are found in a submodule called `.str`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae70196c-4f89-4140-b3de-6f06c8f706e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['letter'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e4e9ab-f272-401b-b74f-3f710b4fbab6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['letter'].str.replace(\"D\", \"ZZZ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d298cabe-f531-4092-b2c5-5596b403b031",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Correcting Strings in the \"Region\" Series\n",
    "\n",
    "**>>>** Remove unnecessary spaces from the region names using the ```str.strip()``` method. Once done, replace the old Series with the new one and display the last graph again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1c49ad-3c75-44f4-8b3b-6442d98a40cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3205de6c-8b45-4086-bacd-bc33f7dcedac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bf24fa-c37b-4cf6-99c6-0bef8f8755e5",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "# Group By and Aggregations\n",
    "\n",
    "## Group By\n",
    "\n",
    "\n",
    "In data science, a \"Groupby\" is an operation that involves splitting a dataset into groups based on one or more criteria. It is a way to break down data into smaller, manageable pieces for analysis.\n",
    "\n",
    "Once data are separated in different groups, we usually apply one or several functions on each different group.\n",
    "\n",
    "## Aggregations\n",
    "\n",
    "\n",
    "\"Aggregations\" refer to the process of applying a mathematical or statistical function to a set of data to obtain a single summary value. Aggregations typically involve operations like sum, mean, median, count, min, max, etc.\n",
    "\n",
    "Aggregations are used to summarize and condense data, providing insights into the overall characteristics of a dataset or specific groups created using groupby.\n",
    "\n",
    "## Exemples\n",
    "\n",
    "Let's imagine we have a library with several books classified with their genre. We can group them and apply the function `.sum()` to check how many books we have for each different categories.\n",
    "\n",
    "<img src=\"files/group_by-sum.jpg\" width=\"90%\" align=\"center\">\n",
    "\n",
    "But we could also apply the function `.mean()` to compute the average.\n",
    "\n",
    "<img src=\"files/group_by-avg.jpg\" width=\"100%\" align=\"center\">\n",
    "\n",
    "[Source](https://learnsql.com/blog/group-by-in-sql-explained/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57d003a-fce8-41e1-91f1-0ca6c1aa655d",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Performing GROUP BY on our datasets\n",
    "\n",
    "### A simple Group By\n",
    "\n",
    "We can create groupby objets without applying a function, and save it for later.\n",
    "\n",
    "**Note**: We're using the parameter ```observed=True``` because our dtype is a category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79ea7e4-1021-49d7-8ba2-ebed273cbdbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.groupby('letter', observed=True) # Data have been grouped by Letter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20247098-19cd-406e-8ab5-eb7ab5cbbefe",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Simple functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f03181-d683-4beb-b568-071f142271af",
   "metadata": {},
   "source": [
    "#### ``.sum()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a09f50-e8c3-4478-96ee-f859ae5ef807",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.groupby('letter', observed=True).sum('value')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591edab5-d235-42cc-a378-6b420facfda1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### ``.count()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab19cf5d-7b2d-4b7e-9292-7fa95b265b6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.groupby('letter', observed=True).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c71a2a2-70b4-4c90-97b0-ccb2ff0aea55",
   "metadata": {},
   "source": [
    "#### ``.mean()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee6044c-c974-440f-a5b6-b703930cc35e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.groupby('letter', observed=True).mean('value')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8e283d-4322-40d5-b546-f618a64f74a0",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### The method ``.agg()``\n",
    "\n",
    "\n",
    "The ```.agg()``` method in Pandas is used to perform aggregation operations on a DataFrame or Series.\n",
    "\n",
    "We can specify one or more aggregation functions that we want to apply to the data. These functions can be built-in functions like ```sum()```, ```mean()```, ```min()```, ```max()```, or custom functions.\n",
    "\n",
    "It can take strings arguments, lists or even dictionaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e7503c-9fd5-4bc4-9536-fb2b8a23bd84",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "#### ``.agg()`` with one function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a11aa2-1023-4eb8-8b25-53fd196a1c6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.groupby('letter', observed=True).agg('mean', numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24af80c6-c0eb-4a94-9e2f-b8e5f7a13a05",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "#### ``.agg()`` with several functions\n",
    "\n",
    "Here we took only the Series \"value\" from the grouped data, and apply three different functions to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666205ad-a1cb-45e1-a818-23b25878d479",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.groupby('letter', observed=True)['value'].agg(['count', 'sum', 'mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db9cac7-6f7b-4bb3-b32a-c9d3c38ec422",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "#### ``.agg()`` with a dict of arguments\n",
    "\n",
    "Passing a dictionnary of arguments allows us to better control the behavior of the aggregation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557ae342-4184-44ac-9110-b2659df2c5ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.groupby('letter', observed=True).agg({\n",
    "        'value' : ['mean','median', 'max', 'min'],\n",
    "        'fruit':  ['count']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cadd7b-9092-4d0a-a5ef-cd7544c4fa1c",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Calculating New Statistics\n",
    "\n",
    "**>>>** Let's examine the total population of each region. Use a groupby operation and the ```.agg()``` function with the 'sum' argument.\n",
    "\n",
    "**Note**: You can use the ```.sort_values()``` function on a DataFrame or Series to sort the result. Read the docstring if you want to learn more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d975e77-01a4-4415-a2c1-939b74195744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fd0f07-0621-41c1-abc3-b09fc797df12",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "# Join\n",
    "\n",
    "Joins allow us to retrieve data from other sources and add them to our existing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eff4af-e234-4b7a-aed1-63c51d5226ac",
   "metadata": {},
   "source": [
    "<img src=\"files/left-outer-join-operation.png\" width=\"50%\" align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16ad7dd-e9fd-483a-9ba6-b31bb364a208",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fruits_df = pd.read_csv(\"data/fruits_kcal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab09a466-e554-4c91-abdc-2a38c64937b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fruits_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d383c921-0448-4a1d-9155-70c8b5d1a215",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.merge(fruits_df, left_on=\"fruit\", right_on=\"name\", how='left')\n",
    "# alternate syntax:\n",
    "#pd.merge(fake_df, fruits_df, left_on=\"fruit\", right_on=\"name\", how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87da085-7072-4864-bf5e-83baaf90ed93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If we want to take only a specific column, and not the entire second df\n",
    "fake_df.merge(fruits_df[\"calories (per 100g)\"], left_on=\"fruit\", right_on=fruits_df[\"name\"], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0324540d-f4fc-486d-897f-daee02b26d4c",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Adding Entry Date to the United Nations\n",
    "\n",
    "### Creating a new DataFrame\n",
    "\n",
    "Some countries are members of the UN, while others are not. Let's retrieve a dataset directly from Wikipedia and perform a join.\n",
    "\n",
    "**>>>** Examine the page https://en.wikipedia.org/wiki/Member_states_of_the_United_Nations.\n",
    "\n",
    "**>>>** Use the ```pd.read_html()``` function to load the table into a DataFrame named \"un_df\". Be aware that this function will return a list of DataFrames, not a single DataFrame. Perform a ```.head()``` to have a look on the data. You might need to install the \"lxml\" library, in that case go to your terminal and run ```pip install lxml```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6ea10a-a076-4899-8119-b1974cda98b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01e93c9-690b-4e8b-93c4-5293f5321fb2",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## The `.map()` method\n",
    "\n",
    "The ``.map()`` method in Pandas is used to apply a function in a Series. The result is a new Series with transformed values based on the function.\n",
    "\n",
    "Let's see some examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca82080-bb32-4750-9169-5fae1a8d543f",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Using a custom function with `.map()`\n",
    "\n",
    "Once we've created a function, `.map()` will apply the function on each element and returns a new Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346f1e10-fa46-47b4-afd5-21d8ac71883e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's define a function\n",
    "def adds_1000(number):\n",
    "    return number + 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4131ee-df38-4bbf-a6e4-9c83ad1bdc9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "adds_1000(123.53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac786f2-da13-41f9-ae90-55cf4518b66e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['value'].map(adds_1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5e71e6-eac9-444d-b5b9-6251f0f5b44d",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## The function `.str.split()`\n",
    "\n",
    "This function belongs to the submodule `.str`. It behaves almost the same way than the `.split()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff09118c-3892-4792-a2b7-1ab7a8d68bd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['numbers_list'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6176a415-734f-40a9-8ac0-b684db47da74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['numbers_list'].str.split()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcb60d1-7073-4b25-89d6-dd06f9ac66de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['numbers_list'].str.split('-')[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f562d6-c5a2-4b94-86c1-9b2a33fe77f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['numbers_list'].str.split('-', expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f422e3a7-ab25-430f-9fec-383c7a9bf296",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Cleaning \"Member state\" and et \"Date of admission\"\n",
    "\n",
    "The columns \"Member state\" and \"Date of admission\" have some issues. Can you spot them?\n",
    "\n",
    "**>>>** Use string manipulation to clean them. The ```.str.split()``` method in conjunction with a ```.map()``` that retrieves the first element of a list is probably one of the simplest methods. A RegEx would also work.\n",
    "\n",
    "**Note**: Don't forget to apply this function both on the Series \"Member state\" and \"Date of admission\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f40e98-ad7b-44f3-bfbc-02645e02fb8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c896ba3f-d485-43b3-b65d-06012394411d",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Cleaning \"Country\"\n",
    "\n",
    "**>>>** In the \"Country\" column, there are still country names with extra spaces. Use ```str.strip()``` to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e67f4e-0945-4927-9658-748594a9971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ce39b359-8b75-4735-8d09-0bdf52f816bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Checkpoint\n",
    "d = {'Country': 'string', 'Region': 'category'}\n",
    "df = pd.read_csv('data/df_checkpoint_1.csv', dtype=d)\n",
    "un_df = pd.read_csv('data/un_df_checkpoint_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bee8607-f3fb-4dd4-b90b-f1dd6f332ccb",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Join\n",
    "\n",
    "**>>>** Now perform the join between \"df\" and \"un_df\" to retrieve the values from the \"Date of admission\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dd0f3b-d502-4172-a257-ab4ded5146ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d671d2-c0b9-4d73-b7f4-64e744583823",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Time format\n",
    "\n",
    "Our \"df\" and \"fake_df\" both contain dates. However if you take a look at it, they're only strings, not dates yet. Pandas can use \"datetime\" objects allowing us to plot and perform operations on them.\n",
    "\n",
    "In order to do so, we can use the function ``pd.to_datetime()`` which will convert our strings to the right format. Sometimes Pandas will be able to infer automatically the date format. But in this case the strings are not standards so we need to pass a *strftime* (string format time) to the parameter \"format\" to tell Python what's the format date.\n",
    "\n",
    "Each % following by a letter means Python is going to replace it with the elements it finds. The next letter that follows the \"%\" is code, the rest of it is just characters which will be erased when converting to the datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674139db-c83a-400e-abb6-6b69efa530ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.to_datetime(fake_df['date'], format='%Hh:%Mm:%Ss %d-%b-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff993a2-f00b-4a0a-ac31-15b504cc433d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Once we're happy with the result, let's create a new Series\n",
    "# that will contain the date in the right format\n",
    "fake_df['date'] = pd.to_datetime(fake_df['date'], format='%Hh:%Mm:%Ss %d-%b-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb025ab2-2fec-448a-96de-66bd76f75022",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can now perform operations on this Series\n",
    "fake_df['date'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32195bea-4c5b-40f4-96ba-19ad5e10d26f",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## The *Series* \"Date of Admission\"\n",
    "\n",
    "**>>>** Change the type of the *Series* \"Date of admission\" using the `pd.to_datetime()` function.\n",
    "\n",
    "**>>>** Next, find the minimum value, maximum value, and mean of the \"Date of admission\" Series that we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f874fa-8ef0-411b-9974-7231fa830a34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d150ed3-bd81-44b2-bda8-954b84e2b1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the min:\n",
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c74e47a-67ae-4779-9021-d33e02238261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the max:\n",
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33729ba-e9c6-4be5-9dfe-dcfd9600321c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display the mean:\n",
    "# Code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bffb152-cff4-4d96-b6d4-c40c872fa50c",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Number of Days Elapsed Since Joining the United Nations\n",
    "\n",
    "To create a date in Pandas, you can use the `pd.to_datetime()` function and provide it with a date string. Feel free to experiment!\n",
    "\n",
    "Some countries joined the UN a long time ago, others quite recently, and some not at all. Let's calculate the duration of their membership.\n",
    "\n",
    "**>>>** To compute those values:\n",
    "\n",
    "- Create a new Series named \"Membership duration (days)\" that will contain, for each country, the duration in the number of days between the date of their accession and January 1, 2024. You can convert a Series of type by adding ```.dt.days``` to extract the number of days.\n",
    "\n",
    "- Then replace the missing values with 0 using the ```fillna()``` function, and finally convert everything to 'int32' using the ```astype()``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ab789c-e2eb-4341-b0e0-266425770868",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b0d586ff-5d35-4a6e-bbd9-68225a4f4beb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Checkpoint\n",
    "d = {'Country': 'string', 'Region': 'category'}\n",
    "df = pd.read_csv('data/df_checkpoint_2.csv', dtype=d)\n",
    "un_df = pd.read_csv('data/un_df_checkpoint_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a745cb68-c5f1-4793-821a-93ab00372155",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "# Correlation\n",
    "\n",
    "Pandas provides many tools for calculating statistics and correlations.\n",
    "\n",
    "## The ```.corr()``` Method\n",
    "\n",
    "[By default](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html), the ```.corr()``` method uses [Pearson's correlation](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient). If applied directly to the DataFrame, columns containing non-numeric data will cause the function to return an error. You can pass ```True``` to the \"numeric_only\" parameter to address this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b0df5e-2598-4110-abef-f03bcd5d46c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['random_values'] = np.random.random(fake_df.shape[0]) # Let's create a Series with random values\n",
    "fake_df.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bcd2ac-4c77-4457-baeb-1dcd20902bf3",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**>>>** Display the correlation coefficients between all our numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34859403-4d7c-413c-a3d5-f3d23f3a2be0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b84a82-d824-4324-9837-01bc2a19d696",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Seaborn and heatmap\n",
    "\n",
    "To improvde the readibility of our output, let's use Seaborn - a libray built on top of matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6d2be6-3ec7-4b7a-9cc8-771e3894407c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(fake_df.corr(numeric_only=True));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2be6df-6159-4b1f-bb61-3614a01d39bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's annot the heatmap and make it range from -1 to 1.\n",
    "sns.heatmap(fake_df.corr(numeric_only=True), vmin=-1, vmax=1, annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1d32d6-ba2e-4913-ae3e-d9f7d4edc3a6",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**>>>** Display the same heatmap for our df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b827e2-7daa-4e89-93fa-b82b57152f9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da587035-9d1b-4ca5-b649-c946cb1706e6",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "# Correlation visualisations\n",
    "\n",
    "When dealing with data, it's always a good thing to look at the data and not just numbers.\n",
    "\n",
    "## Anscombe's quartet\n",
    "\n",
    "Anscombe's quartet comprises four data sets that have nearly identical simple descriptive statistics, yet have very different distributions and appear very different when graphed. ([wikipedia](https://en.wikipedia.org/wiki/Anscombe%27s_quartet))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849b72e4-1c57-42ba-b23f-1d84ab809cac",
   "metadata": {},
   "source": [
    "<img src=\"files/anscombe.png\" width=\"70%\" align=\"center\">\n",
    "\n",
    "\n",
    "| Property                                                  | Value             | Accuracy                                |\n",
    "|-----------------------------------------------------------|-------------------|-----------------------------------------|\n",
    "| Mean of x:                                                | 9                 | exact                                   |\n",
    "| Sample variance of x:                                     | 11                | exact                                   |\n",
    "| Mean of y:                                                | 7.50              | to 2 decimal places                     |\n",
    "| Sample variance of y:                                     | 4.125             | ±0.003                                  |\n",
    "| Correlation between x and y:                              | 0.816             | to 3 decimal places                     |\n",
    "| Linear regression line:                                   | y = 3.00 + 0.500x | to 2 and 3 decimal places, respectively |\n",
    "| Coefficient of determination of the linear regression: R² | 0.67              | to 2 decimal places                     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5161a8b-a3ab-41a9-a44b-4256306adbd0",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### The `sns.pairplot()` function\n",
    "\n",
    "This function is used to create a matrix of scatterplots, also known as a pairwise scatter plot matrix. It's a valuable tool for visualizing the relationships between multiple variables (columns or Series) in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61943a8-7c5e-41e7-a305-2d2e1194af1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(fake_df, diag_kind='kde', kind='reg', plot_kws={'line_kws':{'color':'red'}});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912da2fc-f7ef-423d-a85a-4370cc76bed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='value',\n",
    "           y='random_values',\n",
    "           data=fake_df,\n",
    "           fit_reg=True,\n",
    "           line_kws={'color': 'red'}\n",
    "          );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df137dd1-2c38-427d-b397-7ebb9a347db1",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**>>>** Display the same outputs four our countries df. Use the Series 'Birthrate' and 'GDP ($ per capita)' as x and y for the ```sns.lmplot()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c47d2c-5cac-4574-ba73-296fa6f22211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447ea54c-a406-4197-9491-f9144966790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba358a9-4bbd-4ebc-9922-d583840c6736",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Export\n",
    "\n",
    "You can export your df to various format such as CSV, Excel, JSON and so on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00494dec-5dd6-44c8-8f65-80ba25ea16fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# csv\n",
    "df.to_csv('df_export.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a254b11-fcc9-420e-b75a-210b4772e06e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#json\n",
    "df.to_json('df_export.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
