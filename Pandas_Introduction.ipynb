{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f58b7dcc-0aa8-4dca-8ec0-c4cb3db1312b",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "# Introduction to Pandas üêº\n",
    "\n",
    "üìñ **Pandas üêº** is a Python üêç library that has been created by **Wes McKinney** in 2007 on top of the **Numpy** library, and had become open sourced by the end of 2009. It is widely used in data science, machine learning and data analysis tasks. The name is derived from the term **\"PANel DAta\"** (tabular data), an econometrics term for data sets that include observations over multiple time periods for the same individuals. ([wikipedia](https://en.wikipedia.org/wiki/Pandas_(software)))\n",
    "\n",
    "**Pandas üêº** works well together with other librairies such as **Matplotlib / Seaborn** and, of course, **Numpy**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dc562f-6c3f-4990-876d-5a7ed2eb0292",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"files/pandas_numpy_matplotlib_seaborn.png\" width=\"100%\" align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f9db81-31fe-4489-a401-1ab5e94f2e8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd # We'll use pd as the alias\n",
    "import numpy as np # and np as alias for numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a3057a-0a39-47a0-8607-fb1ff9f92091",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "# Series\n",
    "\n",
    "## Definition\n",
    "\n",
    "üìñ In Pandas üêº, the equivalent of a 1-D NumPy array is called a \"Series,\" often referred to as a \"column.\" This object is very similar to a NumPy array, as it is constructed directly on top of NumPy arrays. This is why they share a number of characteristics. Indeed, like a NumPy array, a Series:\n",
    "\n",
    "- Can be empty or store **values**.\n",
    "- Has a **dtype** (*data type*) - but handles cases where the data in the Series are of different types better.\n",
    "\n",
    "However, Series differ from NumPy arrays since they have something new:\n",
    "\n",
    "- An **index**, which associates a value, often unique, with each entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21b1933-6634-44cc-8b1b-e797f5951dd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a Series from a list:\n",
    "s = pd.Series([87, 23, 12, 43, 52, 61])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ac7d67-01ac-40c0-9717-45b65ca34dd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To access an element, we can use Numpy syntax.\n",
    "s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a3267d-b57b-4036-b607-7f14d8d51f86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaea15c6-7063-4f54-a896-d928ed8f7d19",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Index and Series\n",
    "\n",
    "We can let Pandas üêº decide, as in the previous example, or specify one using the following syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043f5c9c-dd78-424a-8e2f-d5e9e10a5e05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using a list for values and a list for index\n",
    "s = pd.Series([87, 23, 12, 43, 52, 61], index=[100, 102, 104, 106, 108, 110])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f501db-6f2f-4e28-ac99-6f372efc7e59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# or we can provide a dictionary, index is the key, value is value.\n",
    "s = pd.Series({100: 87, 102: 23, 104: 12, 106: 43, 108: 52, 110: 61})\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7dd9ef-b529-4f33-a7e7-fa515da9dae8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Accessing an element with the new index\n",
    "s[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561fe285-adb5-48d8-aa7b-a84892bd83d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s[110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1013b7bd-e219-4c11-9030-fa67e502cbd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can also set strings as index\n",
    "# And index doesn't have to be unique.\n",
    "s = pd.Series([87, 23, 12, 43, 52, 61], index=['Group 1', 'Group 2', 'Group 2', 'Group 2', 'Group 1', 'Group 3'])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22df98fd-fe68-4f1b-a70e-523501c168df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Accessing one or several elements using the new index\n",
    "s['Group 1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d97b0cd-5097-4b42-8067-e936a78c5e76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s['Group 2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55761509-6ba8-4909-bf4e-1a37d988dcbc",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "# DataFrame\n",
    "\n",
    "üìñ A *DataFrame* is a two-dimensional and easily manipulable data structure used to store and manipulate data in Python üêç through Pandas üêº. It is a **collection of Series** (an organised set of Series).\n",
    "\n",
    "Some key characteristics of a Pandas üêº DataFrame:\n",
    "\n",
    "- **Bidimensional**: A DataFrame is often compared to a spreadsheet or an SQL table because it organizes data into rows and columns.\n",
    "\n",
    "- **Resizable**: You can add or remove rows and columns from a DataFrame.\n",
    "\n",
    "- **Named axes**: Rows (axis 0) and columns (axis 1) have labels (names).\n",
    "\n",
    "- **Operations**: DataFrames support a wide range of operations on data, including filtering, grouping, aggregation, pivoting, merging, joining, and so on...\n",
    "\n",
    "- **And many more... !** : handling missing data, export in various formats..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d2a22d-f970-4c7a-8570-8468ddd2d4b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"files/series-and-dataframe.png\" width=\"50%\" align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a65d70-a7fa-4dcf-a04b-eedf1b0bf33c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s1 = pd.Series([87, 23, 12, 43, 52, 61])\n",
    "s2 = pd.Series([100, 52, 35, 71, 62, 89])\n",
    "s3 = pd.Series(['m', 'f', 'm', 'm', 'f', 'f'])\n",
    "\n",
    "# There are multiple ways to create a dataframe from Series.\n",
    "# Let's go with a dictionary. Keys are column names and values are... values!\n",
    "\n",
    "pd.DataFrame({'age': s1, 'weight': s2, 'sex': s3}) # In Jupyter the display of a Dataframe is different from a Series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2570caad-4caa-4098-8204-3f580b889c60",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Creating a DataFrame\n",
    "\n",
    "üìñ Pandas üêº can create DataFrames from many differents file formats including :\n",
    "\n",
    "- CSV (comma separated value)\n",
    "- Excel (XLS and XLSX)\n",
    "- JSON (Java Script Object Notation)\n",
    "- HTML (Tables)\n",
    "- SQL (Databases)\n",
    "- Parquet\n",
    "- HDF5 (Hierarchical Data Format)\n",
    "- Feather\n",
    "- Stata\n",
    "- SAS\n",
    "- Google BigQuery\n",
    "- Clipboard\n",
    "- Python üêç Dictionnaries\n",
    "- URLs (HTTP, FTP, etc.)\n",
    "- ... And many more"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebbc4a0-9f29-425d-a4ca-34f64cb96687",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Fake dataset\n",
    "\n",
    "üëâ Let's create a DataFrame from a CSV file stored inside the \"data\" folder and named \"fake.csv\". We'll use this fake dataset later to demonstrate some of the Pandas üêº functions. Let's store it in a variable named : **\"fake_df\"**.\n",
    "\n",
    "**Note**: Here we're using a naming convention named **\"suffix Hungarian notation\"**, meaning the type of the object is included at the end of its name. And, of course, \"df\" is short for \"DataFrame\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b012afd5-eaa6-4694-a99a-b3586d7d6e26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df = pd.read_csv(\"data/fake.csv\")\n",
    "\n",
    "fake_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fe3ff0-c201-4c40-b53e-fede9073649d",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "üîé If you run the cell above, you can tell right away that \"fake_df\" is a **DataFrame**: columns names and indices are in bold-style. And if you mouse over the DataFrame, rows are highlighted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680c7557-5eb3-4283-b820-7d7eb1f7adf4",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "# The Countries dataset\n",
    "\n",
    "## Presentation\n",
    "\n",
    "üìñ During this tutorial, we will use a well-known dataset that consists of a single file named \"countries.csv\" and contains a large number of different statistics about countries (in 2013).\n",
    "\n",
    "## Objectives\n",
    "\n",
    "We will use this file to examine if there is a correlation between four variables:\n",
    "\n",
    "- population density (expressed in km¬≤), which we will need to compute.\n",
    "- GDP per capita ($)\n",
    "- Birthrate\n",
    "- Deathrate\n",
    "\n",
    "We're going to look at those correlations at two different levels of analysis: at the country level and at the level of the region to which each country belongs.\n",
    "\n",
    "We will also examine whether the duration of their membership in the UN, if they are members, influences our variables to be explained.\n",
    "\n",
    "But before reaching this result, we will need to understand and clean up this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afa9593-f9bc-4a90-9a35-2b84d79524b9",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Reading a CSV file : \"countries.csv\"\n",
    "\n",
    "‚ùì **>>>** Use the ``pd.read_csv()`` function to read the CSV file named \"countries.csv\" which is located inside the \"data\" folder. Store the result in a new DataFrame named \"df\".\n",
    "\n",
    "If you try to read a CSV file and Pandas üêº returns an error, open the file with jupyter lab or a text editor (VS Code, Notepad++ etc.) and examine it to find the source of the error. The most common errors when reading a csv file are:\n",
    "\n",
    "- The **filepath** was not properly given to the function. The easiest way is to move the file you want to read in the same directory than your notebook file (or in a subfolder named \"data\").\n",
    "\n",
    "- A wrong **field separator**, by default Pandas üêº assumes that it is the \",\" character. In this case specify the separator (= delimiter) with the argument \"sep\".\n",
    "\n",
    "- A bad **\"quotechar\"**, a character used to denote the start and end of a quoted item. Quoted items can include the delimiter and it will be ignored. In this case specify it with the \"quotechar\" argument.\n",
    "\n",
    "- The presence of **extra lines** at the beginning or at the end of the file. In this case use the \"skiprows\" or \"skipfooter\" arguments to ignore these lines.\n",
    "\n",
    "- Bad file **encoding**. The \"utf-8\" standard is the most common, but sometimes the files are in other formats like \"cp1252\" for example. In this case specify the encoding with the \"encoding\" argument. Here with the \"countries.csv\" file, the encoding is already 'utf-8'. \n",
    "\n",
    "**NOTE**: Do **NOT** open the file with the sofware \"Excel\", it may corrupt your file and make it unreadable, even if you don't save the modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f91dd39-4729-4510-8fd4-22bd2bcafcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4894468-6e20-48bd-a368-e07ee1e8eb3e",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "# First things to do\n",
    "\n",
    "## The `.shape` attribute\n",
    "\n",
    "üîé We now have two DataFrames \"fake_df\" and \"df\". Let's take a look at our they're shaped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8952bb-2e50-461a-8f0d-a2407415534d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc778ab-4b9c-47c1-9e23-6e60c9577ee2",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "‚ùì **>>>** What shape is our df? What does it mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2375ac7-975b-4392-86bf-dec8900ed68a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5875ea1-231b-4f84-8b7b-ead0e304cc50",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## The ``.head()`` function\n",
    "\n",
    "It returns the first n rows, default is set to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6765fb02-2c49-4b7b-96b2-91c6ae7b1cb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a84850-46ca-41ad-8306-bac3c4829f8d",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "‚ùì **>>>** Use the ``.head()`` function to display the first 2 lines of our df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7116b0b-f256-4ed2-9f77-018f6cf13717",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401c26b4-713d-4a7d-95fa-1f0e8b946c1a",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## The `.columns` attribute\n",
    "\n",
    "It stores the names of our different columns. It is also the index of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9417547b-1377-4feb-8d45-a9a43881d72a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaf55d0-4488-414d-9196-98410dc8f17d",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "‚ùì **>>>** What are the columns of our DataFrame? Use a ``for`` loop to print each column name on a different line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120bb727-0a58-4f3d-a0f8-5d8111daa4b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbf9659-ddd8-4a07-99b3-51915c97f2c3",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## The `.index` attribute\n",
    "\n",
    "It stores the names of the rows (the index)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2fe2b7-507a-421a-a0ee-96af8dd9c3b2",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "‚ùì **>>>** What does the index of df look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434b439f-f3fa-4652-8407-54642c813f79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7103be-d382-42fd-b274-b0d418ed0510",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## The ```.dtypes``` attribute\n",
    "\n",
    "The word ```dtypes``` stand for \"data types\", it stores the types of our different columns. The type \"object\" is often a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe080a4-de3a-424c-9073-1058ea906151",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7539d74a-cc25-4d1c-a226-630cbf221aa6",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "‚ùì **>>>** What are the dtypes of our df?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09233a4-27b2-4315-837a-8ab0c9e5bfcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089403d3-e5c5-4f23-ac85-1e445cf45c3a",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Missing values : the ```.isna()``` method\n",
    "\n",
    "When you're given a new dataset, it is quite important to check if they are missing values. You can use the ```.isna()``` method, it returns a new DataFrame which has the same size than the original df, but the values are ```True``` if the value is missing and ```False``` if a value exists.\n",
    "\n",
    "üí° That's one of the main strength of Python üêç : the outputs of many Pandas üêº functions are also Pandas üêº objects, meaning you can work on your data or your results using the same functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d63f96-8ee1-4257-bd7c-037d7ecc1a45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f085129f-2cc0-4e77-9bff-c3d1c1a3e3d4",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "‚ùì **>>>** Use ```.isna()``` on your DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16da66f-16e2-42ca-ab84-1817f19d6eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eeb562a-8e81-41d5-ba27-16f317e69d89",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Apply a function to a DataFrame : ```isna().sum()```\n",
    "\n",
    "The ```.sum()``` method performs a sum on an entire DataFrame. When performing sums, boolean values are treated as 1 if they're ```True``` and 0 if they're ```False```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaf90c2-551b-4179-99c2-24a5c33efe96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edea25a-e192-4601-9b7d-2330709c1dea",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "‚ùì **>>>** How many missing values in our DataFrame ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9b8df2-a36e-4e29-bea0-1970528a7c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efec20ba-9c90-4cc1-9f84-910ed3767572",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Creating or replacing Series\n",
    "\n",
    "Just like a dictionnary, to create or replace a Series you just have to assign it a value  or an object (list, dict, integer, almost any objects...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9525759-4c0d-48fa-acfa-a0b23131b144",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['one'] = 1\n",
    "fake_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e175db06-f1f6-4d4d-b5b8-9ec227d68687",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['one'] = 999\n",
    "fake_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5ec72a-d3db-4149-835c-d835a087ccd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df[['one', 'two']] = 1\n",
    "fake_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9778e2da-4d75-4ec1-8d75-1e872b63c2ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df[['one', 'two']] = 1, 2 # An implicit tuple\n",
    "fake_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67319b7e-ba24-4a02-b411-6ad5259198c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['three'] = fake_df['one'] + fake_df['two']\n",
    "fake_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f010a02-fbe0-496d-a763-ce22d1b7ee72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['count'] = [el for el in range(fake_df.shape[0])]\n",
    "fake_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23040353-8deb-4fe8-b8fe-e2e08b2677cb",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Dropping a Series\n",
    "\n",
    "There are several ways to \"drop\" (erase / remove / delete) a Series from your DataFrame, one of the easiest is just:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60751b9e-d3a5-4e1d-9a7b-595844fe3173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.drop(columns='one') # This function is not \"in place\" which means we haven't modified \"fake_df\" yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4608925c-518b-4335-9910-40933ed2bff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we're happy with the result\n",
    "# We can replace the old df with the new one\n",
    "fake_df = fake_df.drop(columns='one')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb0f2fd-06b8-4754-9b77-817763ed724c",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "‚ùóÔ∏è**WATCH OUT**‚ùóÔ∏è This time we're not replacing or creating a **Series** we're replacing the whole DataFrame!\n",
    "\n",
    "One can get confused very easily. Luckily if you make a mistake, it's also very easy to go back and re-run the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc509bcc-4ace-43f1-a8b9-70da712de17d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can drop several columns by passing a list.\n",
    "fake_df.drop(columns=['two', 'three', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17afb14c-e8e5-4679-9751-db6ac515bf7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If we're happy with the result\n",
    "# We can replace the old df with the new one\n",
    "fake_df = fake_df.drop(columns=['two', 'three', 'count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85eccab-2620-4866-b255-4ac11cc4d59c",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "‚ùì **>>>** Delete all columns that have the character \"%\" in their name. **Hint**: you can use a comprehensive list and the method ```.drop()``` to do it with only one line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d08193a-3eeb-4115-b30c-c48ba89887d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bec7a2c-6700-44cd-9e68-c0e20da92616",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "# Dealing with data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3093926c-7015-498b-8d4b-ac076fe75223",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Setting the right data types\n",
    "\n",
    "ü§ì Now that we know what is a DataFrame and a Series, and before we start doing something else, it's important that our Series are converted in the right type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc7ceb1-c9b9-43ac-941a-5e49e1802ab0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc597c7-c520-4d2d-8267-9532589f8c8b",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Conversion with `.astype()`\n",
    "\n",
    "There are many different types of dtype. Some of them use standard Python üêç format, some are specific to Pandas üêº and others are common to several other languages (PyArrow).\n",
    "\n",
    "Here let's use either:\n",
    "\n",
    "- `'string'` (which is a Pandas üêº type)\n",
    "- `int` (Python üêç type)\n",
    "- `float` (Python üêç type)\n",
    "- `str` (Python üêç type, but Pandas üêº call it an \"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63de3106-fb53-4c58-8bbe-e21c3dc5df04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# One conversion\n",
    "fake_df['letter'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2da2ed-076f-400f-81e7-fdac83d9d871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Several conversions\n",
    "fake_df[['fruit', 'letter']].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e62766-f253-4362-9e0c-586f65994450",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replacing old Series with new ones\n",
    "fake_df[['fruit', 'letter']] = fake_df[['fruit', 'letter']].astype('string')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba88b606-632a-4d7e-a484-cbad6315be23",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## New import of the \"countries.csv\" file\n",
    "\n",
    "ü§ì A good practice when handling data is to preprocess the file as much as possible during its loading into the computer's memory, paying particular attention to:\n",
    "\n",
    "- The types of the columns (```dtype```).\n",
    "- The importation of decimal numbers (\".\" or \",\" ?)\n",
    "- Loading only the columns of interest into memory.\n",
    "\n",
    "### Setting the right ```dtype``` while loading the data\n",
    "\n",
    "- This is specially important when we work with large databases because a dtype like  ```int``` for instance takes way less space inside the RAM than a string. For strings that are often the same you can use the type ```category``` (but there's no need to use it here, as it is a very small dataset).\n",
    "\n",
    "- When using the function `pd.read_csv()`, we can give to the argument `dtypes` a **dictionary with column names as keys and dtype as value**. We can either type this dictionary or use dict comprehension to generate a template and then edit it."
   ]
  },
  {
   "cell_type": "raw",
   "id": "638c3c4e-2374-4630-b20a-f6c090a90692",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Trick to generate the dictionary of parameters\n",
    "{col : 'string' for col in fake_df.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7bc850-7926-470d-8148-197e0248875c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# copy / paste and edit:\n",
    "d = {'letter': 'string',\n",
    "     'fruit': 'string',\n",
    "     'value': 'float32',\n",
    "     'numbers_list': 'string',\n",
    "     'date': 'string'}\n",
    "\n",
    "fake_df = pd.read_csv(\"data/fake.csv\", dtype=d)\n",
    "fake_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1271571-2125-41e5-b70b-080586b38dc4",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**Note**: If a column is not in the dictionary provided to `pd.read_csv()`, Python üêç will try to infer the dtype."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59722f9-41b7-420a-a646-bffd1d6528d7",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Column Selection During Loading\n",
    "\n",
    "The `pd.read_csv()` method has a `usecols` argument. This allows selecting only specific columns when reading the file. It takes a list as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f26001-e845-4c84-97d6-f25d70465232",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "d = {'letter': 'string',\n",
    "     'fruit': 'string',\n",
    "     'value': 'float32',\n",
    "     'numbers_list': 'string',\n",
    "     'date': 'string'}\n",
    "\n",
    "# Using a list\n",
    "columns_to_load = ['letter', 'fruit','value', 'numbers_list', 'date']\n",
    "\n",
    "fake_df = pd.read_csv(\"data/fake.csv\",\n",
    "                      dtype=d,\n",
    "                      usecols=columns_to_load,\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c558a7e-5f76-4429-b564-f0e57fd0684c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d = {'letter': 'string',\n",
    "     'fruit': 'string',\n",
    "     'value': 'float32',\n",
    "     'numbers_list': 'string',\n",
    "     'date': 'string'}\n",
    "\n",
    "# Or you can use d.keys() !\n",
    "\n",
    "fake_df = pd.read_csv(\"data/fake.csv\",\n",
    "                      dtype=d,\n",
    "                      usecols=d.keys(),\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dec118f-32c9-424d-ae20-012603a8832e",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## New Import of the \"countries.csv\" File\n",
    "\n",
    "### Decimal Numbers: Dot or Comma?\n",
    "\n",
    "Some conventions use a dot to separate the decimals of a number, while others use a comma. You can specify the convention to Pandas üêº during the import by providing the character ```'.'``` or ```','``` to the ```decimal``` parameter of the ```pd.read_csv()``` function. This allows Pandas üêº to automatically infer the correct data type.\n",
    "\n",
    "### New Import\n",
    "\n",
    "‚ùì **>>>** Re-import the DataFrame with **the same parameters as before**, but this time also use:\n",
    "\n",
    "- The ```usecols``` parameter to load only the following columns:\n",
    "    - \"country\"\n",
    "    - \"region\"\n",
    "    - \"population\"\n",
    "    - \"area (km¬≤)\"\n",
    "    - \"gdp ($ per capita)\"\n",
    "    - \"birthrate\"\n",
    "    - \"deathrate\"\n",
    "\n",
    "- The ```dtype``` parameter with the correct data types.\n",
    "    - \"country\" and \"region\" will be of type 'string'.\n",
    "    - \"population\" and \"area (km¬≤)\" will be of type 'int64' (or 'int32' if you want to save some memory).\n",
    "    - \"gdp ($ per capita)\", \"birthrate\", and \"deathrate\" will be of type 'float32'.\n",
    "\n",
    "- The ```decimal``` parameter to specify that the decimal separator used in the file is `','`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094de256-7aa2-44c7-bc64-36f15e2633b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "36f23d77-b3ea-4b10-a7de-1f27529d04d9",
   "metadata": {
    "editable": true,
    "raw_mimetype": "",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Checkpoint 1\n",
    "d = {'country': 'string',\n",
    "    'region': 'string',\n",
    "    'population': 'int32',\n",
    "    'area (km¬≤)': 'int32',\n",
    "    'gdp ($ per capita)': 'float32',\n",
    "    'birthrate': 'float32',\n",
    "    'deathrate': 'float32'}\n",
    "\n",
    "df = pd.read_csv('data/df_checkpoint_1.csv', dtype=d)\n",
    "\n",
    "d = {'letter': 'string',\n",
    "     'fruit': 'string',\n",
    "     'value': 'float32',\n",
    "     'numbers_list': 'string',\n",
    "     'date': 'string'}\n",
    "\n",
    "fake_df = pd.read_csv('data/fake_df_checkpoint_1.csv', dtype=d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee971d3-ba13-4e4f-8277-5c7b6371fb8b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Population Density Calculation\n",
    "\n",
    "Now that our data is clean, we can create our own indicators.\n",
    "\n",
    "‚ùì **>>>** Create a new series named \"density (per km¬≤)\" that calculates the population density for each country. Round it to one decimal place.\n",
    "\n",
    "**Hint**: The `round()` function also works on Series!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2b99a1-55b0-4094-a23f-50bca177c8e4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26f29a0-9c32-472f-8459-0fad19d5b462",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Plotting data\n",
    "\n",
    "Let's go back to our fake_df. You can plot a Series like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb61f2fe-2c90-46e5-8d50-1916d77c4e95",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['value'].plot(); # Adding a semicolon removes useless legend\n",
    "# Note that line stops because there's a missing value (NaN) at index 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c45fd3b-a278-4461-9de7-1c8fefb8d27d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can specify what graph you want with the 'kind' parameter.\n",
    "# Let's use a bar graph first.\n",
    "# Bar graphs are usually used to plot categorical data.\n",
    "# As we want to plot the value for each row of our fake_df, this would work.\n",
    "\n",
    "fake_df['value'].plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8fec7d-abd7-47a2-ba9b-2dd2e9e32da6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "en"
    ]
   },
   "source": [
    "üëâ But the xticks are the index of our DataFrame. Let's plot some values as \"y\" and some categorical values as \"x\". In order to do this, you can use ``.plot()`` directly on a DataFrame, allowing you to manipulate multiple Series easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3050d33a-eee0-471c-8237-987faf10ecb5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.plot(x='letter', y='value', kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d9a7c1-d225-405a-be9c-f60f15d98966",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "en"
    ]
   },
   "source": [
    "## The Series \"population\"\n",
    "\n",
    "‚ùì **>>>** Plot both the Series 'country' and 'population' on the same graph. Use only the first 10 rows of the dataframe to limit the number of information. In order to do so you can slice the df : ```df[:10]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f947f80-bd8e-4e1b-960f-0013e1e01103",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db477883-c846-4418-b868-f01728a5bcfd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Operations on numeric data\n",
    "\n",
    "The Series **'value'** in *fake_df* and **'population'** in *df* are both numerical data. Meaning you can apply many different statistical functions on them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aa559c-f705-4cf8-9044-a7507e02bbad",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['value'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51097083-14fb-4d0a-b5f9-a43a347f52eb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['value'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97435c2-3e68-4556-86d7-d15463bd155a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['value'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ad4ae9-2cbc-43d2-802d-ad9b0007ff00",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "en"
    ]
   },
   "source": [
    "‚ùì **>>>** Have a look at basics statistics on the \"Population\" data. You can use the function `.astype(int)` to convert the result to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646d00bc-4119-4799-a9c0-e4748cededa7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48136f52-d367-443c-b8fc-b83ffbf254f7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Selecting data in Pandas üêº : ``.iloc[]`` and ``.loc[]`` methods\n",
    "\n",
    "The `.iloc[]` and ``.loc[]`` methods in Pandas üêº are used for indexing and selecting data in DataFrames. They serve different purposes and work based on different indexing schemes:\n",
    "\n",
    "### The ``.iloc[]`` method (Integer Location)\n",
    "\n",
    "``.iloc[]`` is primarily used for selecting data by integer position, which means you specify row and column positions numerically :\n",
    "\n",
    "- It accepts integer-based indexing for both rows and columns.\n",
    "- The indexing is zero-based, similar to Python üêç lists.\n",
    "- You can use integers, slices, lists, or boolean arrays to select data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35f01b8-a86c-4f05-a599-6c76a0695b39",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.iloc[0]  # Select the first row\n",
    "# Note that it returns a Series, not a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50d759b-2e2b-41de-888a-ce173aec7865",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.iloc[2:5, 1:3]\n",
    "# Returns a DataFrame because they are several Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2b63cc-63f8-4005-b187-d4714da01e01",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.iloc[[0, 3, 5], [1, 2]]  # Select specific rows and columns by integer positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20095383-60b7-4c17-9830-6487cacc3b2e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select specific rows and columns with boolean indexing\n",
    "fake_df.iloc[[True, False, True, False, True, True, False, True, False, True, False], [False, True, True, False, True]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b93652-37a0-4b7c-8f6c-4f65ec8c417e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "en"
    ]
   },
   "source": [
    "### The ``.loc[]`` method (Label Location)\n",
    "\n",
    "The method ``.iloc[]`` can sometimes be useful, but generally we use the ``.loc[]`` method which is very powerful. It allows us to select data by label or label-based conditions.\n",
    "\n",
    "- It accepts label-based indexing for both rows and columns.\n",
    "- Unlike most of the indexing in Python üêç : the indexing is **inclusive on both ends** (i.e., slices include the specified labels).\n",
    "- You can use labels, slices, lists, or boolean arrays to select data.\n",
    "- You can filter using conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e9a9e0-87e2-4127-bce0-c16809e43279",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.loc[0:3, 'fruit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c11aa22-154e-481d-ba4c-2fb912fe9fcd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.loc[1:2, ['fruit', 'date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16a0141-fe09-422d-ba37-3361e893c061",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Just like .iloc[], you can filter rows and columns using boolean indexing\n",
    "fake_df.loc[[True, False, True, False, True, True, False, True, False, True, False], [False, True, True, False, True]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ca1d22-e06a-4b77-a559-8e0cf247527c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pandas returns a boolean Series when you make comparison\n",
    "fake_df['value'] > 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b9da22-2c05-497b-b52d-dddf00b5de81",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can use this boolean Series to filter your DataFrame using .loc[]\n",
    "fake_df.loc[fake_df['value'] > 500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c615cf7d-a34c-4f62-b267-cbc6e3b3f104",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Population Filtering\n",
    "\n",
    "‚ùì **>>>** Use ```.loc[]``` and ```.plot()``` in order to:\n",
    "\n",
    "- Display a Series with the name of the countries with a population greater than 60 million.\n",
    "- Then generate a new graph with the name of the country (x) and their population (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25e1fd1-f740-4fde-a4d1-f4953e3e0f3c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bad50b-4aa1-4cd6-baa8-9c7650d5151c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12313758-eb42-4a06-a7f8-a20b45aeebe7",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "# Using ```.loc[]``` with Multiple Conditions\n",
    "\n",
    "It is possible filter with multiple conditions within a ```.loc[]```. In that case, we need to use the element-wise operators ```&``` and ```|``` instead of ```and``` and ```or``` to compare element by element. Make sure each condition is enclosed in parentheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bc472c-5810-4cdb-8671-3213525b86a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# yields an error !\n",
    "#fake_df.loc[(fake_df['letter'] == 'D') and (fake_df['value'] > 500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ade0ef-d4d7-4ebe-84ed-38e8327059f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# works with the element-wise operator '&'\n",
    "fake_df.loc[(fake_df['letter'] == 'D') & (fake_df['value'] > 500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a32112d-1a0d-4c73-9b1e-e2f73e5768e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yields an error !\n",
    "#fake_df.loc[(fake_df['letter'] == 'D') or (fake_df['value'] > 500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e118448d-31f0-4715-9705-4ce0ad542b7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# works with the element-wise operator '|'\n",
    "fake_df.loc[(fake_df['letter'] == 'D') | (fake_df['value'] > 500)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8584aa-fb3e-457f-8bef-d69ad6b448cd",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**>>>** Use a ```.loc[]``` and display the countries that a population higher than 100 millions and a GDP per capita higer than $25 000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dc5b54-6456-4175-a45b-eeaba189b6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393d1c70-4fe1-41d7-91b4-462c349a2fb9",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Plotting categorical data\n",
    "\n",
    "If we try to plot a non-numeric Series, we get an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c214dc31-d092-4646-93b7-74022480535e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Yields an error!\n",
    "#df['region'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d83d280-4015-4692-ad72-3a3845492635",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### The method ``value_counts()``\n",
    "\n",
    "This method is very useful, it takes as input almost any Series and return a new Series which displays the number of occurrences for each elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a5d18a-5fcf-4546-b77a-a0321edf758a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['letter'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e5037c-2c60-45ad-a5c3-27d79559ae87",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## The Series \"region\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cae2df-f2a5-4e76-b041-beaf19ff121f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['region']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7adca6f-3101-405f-b49a-05d5bdcef9ae",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "‚ùì **>>>** Use the ```.value_counts()``` method to display the list of different regions and their respective occurrences.\n",
    "\n",
    "‚ùì **>>>** Then generate a graph indicating the frequency of each region using the ``.plot()`` method. Use the \"kind\" parameter to find the right type of graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb0622c-0a33-44cf-8b76-3db072e1e46c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fe2f25-0209-410f-b7f6-3f6e40a926a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f840b8-062f-48b7-ab1e-95226f31eb2f",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## The methods `.unique()` and `.nunique()`\n",
    "\n",
    "- `.unique()` \n",
    "\n",
    "The `.unique()` method is used to return an array of all the unique values present in a Series. In other words, it removes duplicate values and provides a list of unique values.\n",
    "\n",
    "- `.nunique()` \n",
    "\n",
    "The `.nunique()` method is used to count the number of distinct (unique) values in a Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064032cc-61bf-4043-b0aa-ee90d61d46bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['letter'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed42e7e9-a481-4929-8a13-638abecc5f4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['letter'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dbbb16-5642-40c8-849a-8c157d9135ee",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### How many unique values in \"region\"?\n",
    "\n",
    "‚ùì **>>>** Use ```unique()``` and ```.nunique()``` to display unique values and the nmber of uniques values in \"region\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19da0011-7b94-4f36-ab30-5db3fa01048b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755d5555-ff31-47a3-b6e5-4a977792d605",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eb6d04-dd16-4305-a2dd-88f735539863",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## String Manipulation\n",
    "\n",
    "As you can see, the names of the regions appear to have a lot of unnecessary spaces. Pandas üêº provides many functions for working with strings. These are found in a submodule called `.str`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae70196c-4f89-4140-b3de-6f06c8f706e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['letter'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e4e9ab-f272-401b-b74f-3f710b4fbab6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['letter'].str.replace(\"D\", \"ZZZ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d298cabe-f531-4092-b2c5-5596b403b031",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Correcting Strings in the \"region\" Series\n",
    "\n",
    "‚ùì **>>>** Remove unnecessary spaces from the region names using the ```.str.strip()``` method. Once done, replace the old Series with the new one and display the last graph again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1c49ad-3c75-44f4-8b3b-6442d98a40cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bf24fa-c37b-4cf6-99c6-0bef8f8755e5",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "# Group By and Aggregations\n",
    "\n",
    "## Group By\n",
    "\n",
    "\n",
    "In data science, a \"Groupby\" is an operation that involves splitting a dataset into groups based on one or more criteria. It is a way to break down data into smaller, manageable pieces for analysis.\n",
    "\n",
    "Once data are separated in different groups, we usually apply one or several functions on each different group.\n",
    "\n",
    "## Aggregations\n",
    "\n",
    "\n",
    "\"Aggregations\" refer to the process of applying a mathematical or statistical function to a set of data to obtain a single summary value. Aggregations typically involve operations like sum, mean, median, count, min, max, etc.\n",
    "\n",
    "Aggregations are used to summarize and condense data, providing insights into the overall characteristics of a dataset or specific groups created using groupby.\n",
    "\n",
    "## Exemples\n",
    "\n",
    "Let's imagine we have a library with several books classified with their genre. We can group them and apply the function `.sum()` to check how many books we have for each different categories.\n",
    "\n",
    "<img src=\"files/group_by-sum.jpg\" width=\"90%\" align=\"center\">\n",
    "\n",
    "But we could also apply the function `.mean()` to compute the average.\n",
    "\n",
    "<img src=\"files/group_by-avg.jpg\" width=\"100%\" align=\"center\">\n",
    "\n",
    "[Source](https://learnsql.com/blog/group-by-in-sql-explained/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57d003a-fce8-41e1-91f1-0ca6c1aa655d",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Performing GROUP BY on our datasets\n",
    "\n",
    "### A simple Group By\n",
    "\n",
    "We can create groupby objets without applying a function, and save it for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79ea7e4-1021-49d7-8ba2-ebed273cbdbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.groupby('letter') # Data have been grouped by Letter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20247098-19cd-406e-8ab5-eb7ab5cbbefe",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Simple functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f03181-d683-4beb-b568-071f142271af",
   "metadata": {},
   "source": [
    "#### ``.sum()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a09f50-e8c3-4478-96ee-f859ae5ef807",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.groupby('letter').sum('value')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591edab5-d235-42cc-a378-6b420facfda1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### ``.count()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab19cf5d-7b2d-4b7e-9292-7fa95b265b6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.groupby('letter').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c71a2a2-70b4-4c90-97b0-ccb2ff0aea55",
   "metadata": {},
   "source": [
    "#### ``.mean()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee6044c-c974-440f-a5b6-b703930cc35e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.groupby('letter').mean('value')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8e283d-4322-40d5-b546-f618a64f74a0",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### The method ``.agg()``\n",
    "\n",
    "\n",
    "The ```.agg()``` method in Pandas üêº is used to perform aggregation operations on a DataFrame or Series.\n",
    "\n",
    "We can specify one or more aggregation functions that we want to apply to the data. These functions can be built-in functions like ```sum()```, ```mean()```, ```min()```, ```max()```, or custom functions.\n",
    "\n",
    "It can take strings arguments, lists or even dictionaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e7503c-9fd5-4bc4-9536-fb2b8a23bd84",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "#### ``.agg()`` with one function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a11aa2-1023-4eb8-8b25-53fd196a1c6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.groupby('letter').agg('mean', numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24af80c6-c0eb-4a94-9e2f-b8e5f7a13a05",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "#### ``.agg()`` with several functions\n",
    "\n",
    "Here we took only the Series \"value\" from the grouped data, and apply three different functions to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666205ad-a1cb-45e1-a818-23b25878d479",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.groupby('letter')['value'].agg(['count', 'sum', 'mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db9cac7-6f7b-4bb3-b32a-c9d3c38ec422",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "#### ```.agg()``` with a dict of arguments\n",
    "\n",
    "Passing a dictionnary of arguments is very common, allowing us to better control the behavior of the aggregation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557ae342-4184-44ac-9110-b2659df2c5ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.groupby('letter').agg({\n",
    "        'value' : ['mean','median', 'max', 'min'],\n",
    "        'fruit':  ['count']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b833bba",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "#### ```.agg()``` with *kwargs*\n",
    "You can also use keyword arguments (kwargs) to specify the aggregation functions you want to apply to each column in a DataFrame. This method allows you to assign **custom names** to the resulting columns after aggregation and **does not output a MultiIndex DataFrame**.\n",
    "\n",
    "So you could write the previous code as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe507089",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_df.groupby('letter').agg(\n",
    "    value_mean=('value', 'mean'),\n",
    "    value_median=('value', 'median'),\n",
    "    value_max=('value', 'max'),\n",
    "    value_min=('value', 'min'),\n",
    "    fruit_count=('fruit', 'count')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cadd7b-9092-4d0a-a5ef-cd7544c4fa1c",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Calculating New Statistics\n",
    "\n",
    "‚ùì **>>>** Let's examine the total population of each region. Use a groupby operation and the ```.agg()``` function with the 'sum' argument.\n",
    "\n",
    "**Note**: You can use the ```.sort_values()``` function on a DataFrame or Series to sort the result. Read the docstring if you want to learn more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d975e77-01a4-4415-a2c1-939b74195744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0324540d-f4fc-486d-897f-daee02b26d4c",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "# Working with a new dataset\n",
    "\n",
    "One of the objectives set during the course is to retrieve a new piece of information: the duration of membership in the UN. Some countries have been members since the creation of the UN, while others have never joined.\n",
    "\n",
    "### Creating a new DataFrame\n",
    "\n",
    "Let's retrieve a dataset directly from Wikipedia and perform a join.\n",
    "\n",
    "‚ùì **>>>** Examine the page https://en.wikipedia.org/wiki/Member_states_of_the_United_Nations.\n",
    "\n",
    "‚ùì **>>>** Use the ```pd.read_html()``` function to load the table into a DataFrame named \"un_df\". Be aware that this function will return a list of DataFrames, not a single DataFrame. Perform a ```.head()``` to have a look on the data. You might need to install the \"lxml\" library, in that case go to your terminal and run ```pip install lxml```.\n",
    "\n",
    "‚ùì **>>>** If you get an error 403, forbidden access, try using a different user-agent in your request headers. You can do this by using the `requests` library to fetch the HTML content and then pass it to `pd.read_html()`. Also the library [fake-headers](https://pypi.org/project/fake-headers/) can be useful.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6ea10a-a076-4899-8119-b1974cda98b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34e5df4-1a67-417e-8ec6-48795752de7b",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Format the column names\n",
    "\n",
    "Let's use only lower case for the columns of our new DataFrame called \"un_df\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d29b59-2a37-4d5c-bd4a-2803cd9e8c9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "un_df.columns = [col.lower() for col in un_df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5e71e6-eac9-444d-b5b9-6251f0f5b44d",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## The function `.str.split()`\n",
    "\n",
    "This function belongs to the submodule `.str`. It behaves almost the same way than the `.split()` function. The ```expand``` parameter is often very useful, it can turn into new Series each element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff09118c-3892-4792-a2b7-1ab7a8d68bd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['numbers_list'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6176a415-734f-40a9-8ac0-b684db47da74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['numbers_list'].str.split()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcb60d1-7073-4b25-89d6-dd06f9ac66de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['numbers_list'].str.split('-')[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f562d6-c5a2-4b94-86c1-9b2a33fe77f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['numbers_list'].str.split('-', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cd29c2-80a4-433c-8a6c-c5d6b16835dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['numbers_list'].str.split('-', expand=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f422e3a7-ab25-430f-9fec-383c7a9bf296",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Cleaning \"member state\" and et \"date of admission\"\n",
    "\n",
    "The columns \"member state\" and \"date of admission\" have some issues. Can you spot them?\n",
    "\n",
    "‚ùì **>>>** Use the ```.str.split()``` method (and its parameter ```expand```) to clean the Series.\n",
    "\n",
    "**Note**: Don't forget to apply, and then replace, this function both on the Series \"member state\" and \"date of admission\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f40e98-ad7b-44f3-bfbc-02645e02fb8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01e93c9-690b-4e8b-93c4-5293f5321fb2",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## The `.map()` method\n",
    "\n",
    "The ``.map()`` method in Pandas üêº is used to apply a function in a Series. The result is a new Series with transformed values based on the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346f1e10-fa46-47b4-afd5-21d8ac71883e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's define a function\n",
    "def adds_1000(number):\n",
    "    return number + 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4131ee-df38-4bbf-a6e4-9c83ad1bdc9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "adds_1000(123.53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac786f2-da13-41f9-ae90-55cf4518b66e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['value'].map(adds_1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f706fef1-0cdc-410f-8a6c-e88b72be66ee",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Fixing the \"original member\" Series\n",
    "\n",
    "A country is considered an \"original member\" if it joined in 1945. Let's recreate this Series.\n",
    "\n",
    "‚ùì **>>>** Create a `.map()` function that:\n",
    "\n",
    "- Takes a string (the date) as input, which we will call \"s\".\n",
    "- Returns `True` if this string indicates that the country joined in 1945 and `False` if it joined at another time.\n",
    "\n",
    "Then apply your function to the \"date of admission\" Series but store the result in the \"original member\" Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae8c733-9c70-4c75-a044-582b2d5dfab5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here !\n",
    "\n",
    "def is_original_member(s):\n",
    "    \n",
    "    ... # Delete the ellipsis and write your function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c896ba3f-d485-43b3-b65d-06012394411d",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Cleaning \"country\"\n",
    "\n",
    "‚ùì **>>>** In the \"country\" column, there are still country names with extra spaces. Use ```str.strip()``` to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e67f4e-0945-4927-9658-748594a9971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "06b6b81f-8fd8-4eb1-bbf5-9685cd9975b0",
   "metadata": {
    "editable": true,
    "raw_mimetype": "",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Checkpoint 2\n",
    "d = {'country': 'string',\n",
    "    'region': 'string',\n",
    "    'population': 'int32',\n",
    "    'area (km¬≤)': 'int32',\n",
    "    'gdp ($ per capita)': 'float32',\n",
    "    'birthrate': 'float32',\n",
    "    'deathrate': 'float32'}\n",
    "\n",
    "df = pd.read_csv('data/df_checkpoint_2.csv', dtype=d)\n",
    "\n",
    "d = {'letter': 'string',\n",
    "     'fruit': 'string',\n",
    "     'value': 'float32',\n",
    "     'numbers_list': 'string',\n",
    "     'date': 'string'}\n",
    "\n",
    "fake_df = pd.read_csv('data/fake_df_checkpoint_2.csv', dtype=d)\n",
    "\n",
    "un_df = pd.read_csv('data/un_df_checkpoint_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fd0f07-0621-41c1-abc3-b09fc797df12",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "# Join\n",
    "\n",
    "Joins allow us to retrieve data from other sources and add them to our existing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eff4af-e234-4b7a-aed1-63c51d5226ac",
   "metadata": {},
   "source": [
    "<img src=\"files/left-outer-join-operation.png\" width=\"50%\" align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16ad7dd-e9fd-483a-9ba6-b31bb364a208",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fruits_df = pd.read_csv(\"data/fruits_kcal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab09a466-e554-4c91-abdc-2a38c64937b4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fruits_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d383c921-0448-4a1d-9155-70c8b5d1a215",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.merge(fruits_df, left_on=\"fruit\", right_on=\"name\", how='left')\n",
    "# alternate syntax:\n",
    "#pd.merge(fake_df, fruits_df, left_on=\"fruit\", right_on=\"name\", how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87da085-7072-4864-bf5e-83baaf90ed93",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If we want to take only a specific column, and not the entire second df\n",
    "fake_df.merge(fruits_df[\"calories (per 100g)\"], left_on=\"fruit\", right_on=fruits_df[\"name\"], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bee8607-f3fb-4dd4-b90b-f1dd6f332ccb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Join\n",
    "\n",
    "‚ùì **>>>** Now perform the join between \"df\" and \"un_df\" to retrieve the values from the \"Date of admission\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dd0f3b-d502-4172-a257-ab4ded5146ce",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d671d2-c0b9-4d73-b7f4-64e744583823",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Time format\n",
    "\n",
    "Our \"df\" and \"fake_df\" both contain dates. However if you take a look at it, they're only strings, not dates yet. Pandas üêº can use \"datetime\" objects allowing us to plot and perform operations on them.\n",
    "\n",
    "In order to do so, we can use the function ``pd.to_datetime()`` which will convert our strings to the right format. Sometimes Pandas üêº will be able to infer automatically the date format. But in this case the strings are not standards so we need to pass a *strftime* (string format time) to the parameter \"format\" to tell Python üêç what's the format date.\n",
    "\n",
    "Each % following by a letter means Python üêç is going to replace it with the elements it finds. The next letter that follows the \"%\" is code, the rest of it is just characters which will be erased when converting to the datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674139db-c83a-400e-abb6-6b69efa530ba",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.to_datetime(fake_df['date'], format='%Hh:%Mm:%Ss %d-%b-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff993a2-f00b-4a0a-ac31-15b504cc433d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Once we're happy with the result, let's create a new Series\n",
    "# that will contain the date in the right format\n",
    "fake_df['date'] = pd.to_datetime(fake_df['date'], format='%Hh:%Mm:%Ss %d-%b-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb025ab2-2fec-448a-96de-66bd76f75022",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can now perform operations on this Series\n",
    "fake_df['date'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32195bea-4c5b-40f4-96ba-19ad5e10d26f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "en"
    ]
   },
   "source": [
    "## The *Series* \"date of admission\"\n",
    "\n",
    "‚ùì **>>>** Change the type of the *Series* \"date of admission\" using the `pd.to_datetime()` function.\n",
    "\n",
    "‚ùì **>>>** Next, find the minimum value, maximum value, and mean of the \"date of admission\" Series that we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f874fa-8ef0-411b-9974-7231fa830a34",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d150ed3-bd81-44b2-bda8-954b84e2b1cf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display the min:\n",
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c74e47a-67ae-4779-9021-d33e02238261",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display the max:\n",
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33729ba-e9c6-4be5-9dfe-dcfd9600321c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display the mean:\n",
    "# Code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bffb152-cff4-4d96-b6d4-c40c872fa50c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Number of Days Elapsed Since Joining the United Nations\n",
    "\n",
    "To create a date in Pandas üêº, you can use the `pd.to_datetime()` function and provide it with a date string. Feel free to experiment!\n",
    "\n",
    "Some countries joined the UN a long time ago, others quite recently, and some not at all. Let's calculate the duration of their membership.\n",
    "\n",
    "‚ùì **>>>** To compute those values:\n",
    "\n",
    "- Create a new Series named \"membership duration (days)\" that will contain, for each country, the duration in the number of days between the date of their accession and January 1, 2024. You can convert a Series of type by adding ```.dt.days``` to extract the number of days.\n",
    "\n",
    "- Then replace the missing values with 0 using the ```fillna()``` function, and finally convert everything to 'int32' using the ```astype()``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ab789c-e2eb-4341-b0e0-266425770868",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7a61cf23-cf15-4031-bb5b-c4a4f5660d8f",
   "metadata": {
    "editable": true,
    "raw_mimetype": "",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Checkpoint 3\n",
    "d = {'country': 'string',\n",
    "    'region': 'string',\n",
    "    'population': 'int32',\n",
    "    'area (km¬≤)': 'int32',\n",
    "    'gdp ($ per capita)': 'float32',\n",
    "    'birthrate': 'float32',\n",
    "    'deathrate': 'float32'}\n",
    "\n",
    "df = pd.read_csv('data/df_checkpoint_3.csv', dtype=d)\n",
    "\n",
    "d = {'letter': 'string',\n",
    "     'fruit': 'string',\n",
    "     'value': 'float32',\n",
    "     'numbers_list': 'string',\n",
    "     'date': 'string'}\n",
    "\n",
    "fake_df = pd.read_csv('data/fake_df_checkpoint_3.csv', dtype=d)\n",
    "\n",
    "un_df = pd.read_csv('data/un_df_checkpoint_3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a745cb68-c5f1-4793-821a-93ab00372155",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "en"
    ]
   },
   "source": [
    "# Correlation\n",
    "\n",
    "Pandas üêº provides many tools for calculating statistics and correlations.\n",
    "\n",
    "## The ```.corr()``` Method\n",
    "\n",
    "[By default](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html), the ```.corr()``` method uses [Pearson's correlation](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient). If applied directly to the DataFrame, columns containing non-numeric data will cause the function to return an error. You can pass ```True``` to the \"numeric_only\" parameter to address this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b0df5e-2598-4110-abef-f03bcd5d46c5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['random_value'] = np.random.random(fake_df.shape[0]) # Let's create a Series with random values\n",
    "fake_df.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bcd2ac-4c77-4457-baeb-1dcd20902bf3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "en"
    ]
   },
   "source": [
    "‚ùì **>>>** Display the correlation coefficients between all our numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34859403-4d7c-413c-a3d5-f3d23f3a2be0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b84a82-d824-4324-9837-01bc2a19d696",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Seaborn and heatmap\n",
    "\n",
    "To improvde the readibility of our output, let's use Seaborn - a libray built on top of matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6d2be6-3ec7-4b7a-9cc8-771e3894407c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(fake_df.corr(numeric_only=True));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2be6df-6159-4b1f-bb61-3614a01d39bf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's annot the heatmap and make it range from -1 to 1.\n",
    "sns.heatmap(fake_df.corr(numeric_only=True), vmin=-1, vmax=1, annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1d32d6-ba2e-4913-ae3e-d9f7d4edc3a6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "en"
    ]
   },
   "source": [
    "‚ùì **>>>** Display the same heatmap for our df. Then do the same thing but for the df grouped by region. Use the mean as aggregation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660b07ef-f27d-4c86-b266-91db332979fb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b827e2-7daa-4e89-93fa-b82b57152f9b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da587035-9d1b-4ca5-b649-c946cb1706e6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "en"
    ]
   },
   "source": [
    "# Correlation visualisations\n",
    "\n",
    "When dealing with data, it's always a good thing to look at the data and not just numbers.\n",
    "\n",
    "## Anscombe's quartet\n",
    "\n",
    "Anscombe's quartet comprises four data sets that have nearly identical simple descriptive statistics, yet have very different distributions and appear very different when graphed. ([wikipedia](https://en.wikipedia.org/wiki/Anscombe%27s_quartet))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849b72e4-1c57-42ba-b23f-1d84ab809cac",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<img src=\"files/anscombe.png\" width=\"70%\" align=\"center\">\n",
    "\n",
    "\n",
    "| Property                                                  | Value             | Accuracy                                |\n",
    "|-----------------------------------------------------------|-------------------|-----------------------------------------|\n",
    "| Mean of x:                                                | 9                 | exact                                   |\n",
    "| Sample variance of x:                                     | 11                | exact                                   |\n",
    "| Mean of y:                                                | 7.50              | to 2 decimal places                     |\n",
    "| Sample variance of y:                                     | 4.125             | ¬±0.003                                  |\n",
    "| Correlation between x and y:                              | 0.816             | to 3 decimal places                     |\n",
    "| Linear regression line:                                   | y = 3.00 + 0.500x | to 2 and 3 decimal places, respectively |\n",
    "| Coefficient of determination of the linear regression: R¬≤ | 0.67              | to 2 decimal places                     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5161a8b-a3ab-41a9-a44b-4256306adbd0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "en"
    ]
   },
   "source": [
    "### The `sns.pairplot()` function\n",
    "\n",
    "This function is used to create a matrix of scatterplots, also known as a pairwise scatter plot matrix. It's a valuable tool for visualizing the relationships between multiple variables (columns or Series) in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61943a8-7c5e-41e7-a305-2d2e1194af1d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.pairplot(fake_df, diag_kind='kde', kind='reg', plot_kws={'line_kws':{'color':'red'}});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8dbbe3-7ca8-4b12-9245-e7ac0dc46bad",
   "metadata": {
    "tags": []
   },
   "source": [
    "### La fonction `sns.lmplot()`\n",
    "\n",
    "Cette fonction permet de visualiser un mod√®le lin√©aire (Linear Model -> LM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24ca33e-b845-4426-a45c-687d80098083",
   "metadata": {},
   "source": [
    "### The `sns.lmplot()` function\n",
    "\n",
    "This function can be used to visualize a linear model (LM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912da2fc-f7ef-423d-a85a-4370cc76bed6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x='value',\n",
    "           y='random_value',\n",
    "           data=fake_df,\n",
    "           fit_reg=True,\n",
    "           line_kws={'color': 'red'}\n",
    "          );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8efaed-b64c-4bbe-ae62-3d59e7e24cfb",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Accessing the Parameters of the Linear Model\n",
    "\n",
    "Seaborn uses the ```stats.linregress``` function from the ```scipy``` library to create this graph. If we want to retrieve the parameters, we can also use this function.\n",
    "\n",
    "Since one of the values in our `fake_df` is missing, we will use the same dataset but remove the rows that have at least one null value in any of their columns with the method ```.dropna()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f43d6c9-1c45-4e92-9274-29ca8bf9ab73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "stats.linregress(fake_df.dropna()['value'], fake_df.dropna()['random_value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df137dd1-2c38-427d-b397-7ebb9a347db1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "en"
    ]
   },
   "source": [
    "‚ùì **>>>**\n",
    "- Use ```sns.pairplot()``` on our country dataframe. Take a look at it, does that make sense?\n",
    "- Then use the Series 'birthrate' and 'gdp ($ per capita)' as x and y for the ```sns.lmplot()```.\n",
    "- Display its slope and its intercept.\n",
    "- This relationship seems to work better with a non-linear model such as polynomial regression. Use the `order` parameter to refine your model.\n",
    "- When the `order` parameter of `sns.lmplot()` is greater than 1, it is `np.polyfit()` that is used by the library. Read the [documentation](https://numpy.org/doc/2.0/reference/generated/numpy.polyfit.html) and use this function to retrieve the parameters of our new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c47d2c-5cac-4574-ba73-296fa6f22211",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here! (pairplot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447ea54c-a406-4197-9491-f9144966790f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here! (lmplot on x= birthrate and y = gdp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078eff90-5fbb-4332-b99f-749f0ffe79ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here! (get the slope and the intercept of the previous graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3307817-5051-4c40-8784-d28765ef16db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here! (lmplot with a non linear model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20fa2db-c577-4f9e-84a4-7f547407c6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here! (get the parameters of our non linear model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fd6d8a-91aa-4de5-9b32-2cdb7372c6e7",
   "metadata": {},
   "source": [
    "## Exporter une image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39cbf03-5879-4e13-bdae-e9dcdf5aa37b",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Export an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedfcdfd-b4ae-4ae9-8a06-37989ec037b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_graph = sns.lmplot(x='area (km¬≤)',\n",
    "                      y='population',\n",
    "                      data=df,\n",
    "                      fit_reg=True,\n",
    "                      line_kws={'color': 'red'}\n",
    "                      );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e1e346-ab4d-49c3-b024-ee42ec150f6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_graph.savefig(\"graph_to_save.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba358a9-4bbd-4ebc-9922-d583840c6736",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Export\n",
    "\n",
    "üèÅ You can export your df to various format such as CSV, Excel, JSON and so on... üíæ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b6446d-2789-4f0d-b309-393cf91328ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# csv\n",
    "df.to_csv('df_export.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380c7cc6-58e7-4c5e-b312-7d5aee866133",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#json\n",
    "df.to_json('df_export.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
