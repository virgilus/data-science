{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f58b7dcc-0aa8-4dca-8ec0-c4cb3db1312b",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "# Introduction to Pandas\n",
    "\n",
    "**Pandas** is a python library that has been created by **Wes McKinney** in 2007 on top of the **Numpy** library, and had become open sourced by the end of 2009. It is widely used in data science, machine learning and data analysis tasks. The name is derived from the term **\"PANel DAta\"** (tabular data), an econometrics term for data sets that include observations over multiple time periods for the same individuals. ([wikipedia](https://en.wikipedia.org/wiki/Pandas_(software)))\n",
    "\n",
    "**Pandas** works well together with other librairies such as **Matplotlib / Seaborn** and, of course, **Numpy**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dc562f-6c3f-4990-876d-5a7ed2eb0292",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"files/pandas_numpy_matplotlib_seaborn.png\" width=\"100%\" align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f9db81-31fe-4489-a401-1ab5e94f2e8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd # We'll use pd as the alias\n",
    "import numpy as np # and np as alias for numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55761509-6ba8-4909-bf4e-1a37d988dcbc",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "# DataFrame\n",
    "\n",
    "A Pandas DataFrame is a two-dimensional, size-mutable, and highly flexible data structure for data manipulation and analysis in Python. The DataFrame is often compared to a spreadsheet or a SQL table, as it organizes data into rows and columns, making it easy to work with structured data.\n",
    "\n",
    "Key characteristics of a Pandas DataFrame:\n",
    "\n",
    "- **Two-Dimensional**: A DataFrame consists of rows and columns, much like a table in a relational database or an Excel spreadsheet.\n",
    "\n",
    "- **Size-Mutable**: You can add or remove rows and columns from a DataFrame, making it adaptable to changing data.\n",
    "\n",
    "- **Labeled Axes**: Both rows and columns have labels (index and column names), allowing for easy identification and indexing of data.\n",
    "\n",
    "- **Mixed Data Types**: A DataFrame can contain data of different types (e.g., integers, floats, strings) in different columns, or inside the same column.\n",
    "\n",
    "- **Missing Data Handling**: DataFrames can handle missing or NaN (Not-a-Number) values gracefully, providing tools for detecting, removing, or imputing missing data.\n",
    "\n",
    "- **Operations**: DataFrames support a wide range of data operations, including filtering, grouping, aggregation, pivoting, merging, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2570caad-4caa-4098-8204-3f580b889c60",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Creating a DataFrame\n",
    "\n",
    "Pandas can create DataFrames from many differents file formats including :\n",
    "\n",
    "- CSV (comma separated value)\n",
    "- Excel (XLS and XLSX)\n",
    "- JSON (Java Script Object Notation)\n",
    "- HTML (Tables)\n",
    "- SQL (Databases)\n",
    "- Parquet\n",
    "- HDF5 (Hierarchical Data Format)\n",
    "- Feather\n",
    "- Stata\n",
    "- SAS\n",
    "- Google BigQuery\n",
    "- Clipboard\n",
    "- Python Dictionnaries\n",
    "- URLs (HTTP, FTP, etc.)\n",
    "- ... And many more"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebbc4a0-9f29-425d-a4ca-34f64cb96687",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Fake dataset\n",
    "\n",
    "Let's create a DataFrame from a CSV file stored inside the \"data\" folder and named \"fake.csv\". We'll use this fake dataset later to demonstrate some of the Pandas functions. Let's store it in a variable named : **\"fake_df\"**.\n",
    "\n",
    "**Note**: Here we're using a naming convention named **\"suffix Hungarian notation\"**, meaning the type of the object is included at the end of its name. And, of course, \"df\" is short for \"DataFrame\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b012afd5-eaa6-4694-a99a-b3586d7d6e26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df = pd.read_csv(\"data/fake.csv\")\n",
    "\n",
    "fake_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fe3ff0-c201-4c40-b53e-fede9073649d",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "If you run the cell above, you can tell right away that \"fake_df\" is a **DataFrame**: columns names and indices are in bold-style. And if you mouse over the DataFrame, rows are highlighted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afa9593-f9bc-4a90-9a35-2b84d79524b9",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Reading a CSV file : \"survey.csv\"\n",
    "\n",
    "**>>>** Use the ``pd.read_csv()`` function to read the CSV file named \"survey.csv\" which is located inside the \"data\" folder. Store the result in a new DataFrame named \"df\".\n",
    "\n",
    "If you try to read a CSV file and Pandas returns an error, open the file with jupyter lab or a text editor (VS Code, Notepad++ etc.) and examine it to find the source of the error. The most common errors when reading a csv file are:\n",
    "\n",
    "- The **filepath** was not properly given to the function. The easiest way is to move the file you want to read in the same directory than your notebook file (or in a subfolder named \"data\").\n",
    "\n",
    "- A wrong **field separator**, by default Pandas assumes that it is the \",\" character. In this case specify the separator (= delimiter) with the argument \"sep\".\n",
    "\n",
    "- A bad **\"quotechar\"**, a character used to denote the start and end of a quoted item. Quoted items can include the delimiter and it will be ignored. In this case specify it with the \"quotechar\" argument.\n",
    "\n",
    "- Bad file **encoding**. The \"utf-8\" standard is the most common, but sometimes the files are in other formats like \"cp1252\" for example. In this case specify the encoding with the \"encoding\" argument.\n",
    "\n",
    "- The presence of **extra lines** at the beginning or at the end of the file. In this case use the \"skiprows\" or \"skipfooter\" arguments to ignore these lines.\n",
    "\n",
    "**NOTE**: Do **NOT** open the file with the sofware \"Excel\", it may corrupt your file and make it unreadable, even if you don't save the modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f91dd39-4729-4510-8fd4-22bd2bcafcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4894468-6e20-48bd-a368-e07ee1e8eb3e",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "# First things to do\n",
    "\n",
    "## The `.shape` property\n",
    "\n",
    "We now have two DataFrames \"fake_df\" and \"df\". Let's take a look at our they're shaped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8952bb-2e50-461a-8f0d-a2407415534d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc778ab-4b9c-47c1-9e23-6e60c9577ee2",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**>>>** What shape is our df? What does it mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2375ac7-975b-4392-86bf-dec8900ed68a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5875ea1-231b-4f84-8b7b-ead0e304cc50",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## The ``.head()`` function\n",
    "\n",
    "It returns the first n rows, default is set to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6765fb02-2c49-4b7b-96b2-91c6ae7b1cb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a84850-46ca-41ad-8306-bac3c4829f8d",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**>>>** Use the ``.head()`` function to display the first 2 lines of our df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7116b0b-f256-4ed2-9f77-018f6cf13717",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401c26b4-713d-4a7d-95fa-1f0e8b946c1a",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## The `.columns` property\n",
    "\n",
    "It stores the names of our different columns. It is also the index of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9417547b-1377-4feb-8d45-a9a43881d72a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaf55d0-4488-414d-9196-98410dc8f17d",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**>>>** What are the columns of our DataFrame? Use a ``for`` loop to print each column name on a different line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120bb727-0a58-4f3d-a0f8-5d8111daa4b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbf9659-ddd8-4a07-99b3-51915c97f2c3",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## The `.index` property\n",
    "\n",
    "It stores the names of the rows (the index)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2fe2b7-507a-421a-a0ee-96af8dd9c3b2",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**>>>** What are the rows of our df? Use a ``for`` loop to print each row index on a different line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434b439f-f3fa-4652-8407-54642c813f79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7103be-d382-42fd-b274-b0d418ed0510",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## The `.dtypes` property\n",
    "\n",
    "The word `dtypes` stand for \"data types\", it stores the types of our different columns. The type \"object\" is often a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe080a4-de3a-424c-9073-1058ea906151",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7539d74a-cc25-4d1c-a226-630cbf221aa6",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**>>>** What are the dtypes of our df?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09233a4-27b2-4315-837a-8ab0c9e5bfcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089403d3-e5c5-4f23-ac85-1e445cf45c3a",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Missing values : the `.isna()` method\n",
    "\n",
    "When you're given a new dataset, it is quite important to check if they are missing values. You can use the ``.isna()`` method, it returns a new DataFrame which has the same size than the original df, but the values are ``True`` if the value is missing and ``False`` if a value exists.\n",
    "\n",
    "That's one of the main strength of python : the outputs of many Pandas functions are also Pandas objects, meaning you can work on your data or your results using the same functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d63f96-8ee1-4257-bd7c-037d7ecc1a45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f085129f-2cc0-4e77-9bff-c3d1c1a3e3d4",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**>>>** Use ``.isna()`` on your DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16da66f-16e2-42ca-ab84-1817f19d6eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eeb562a-8e81-41d5-ba27-16f317e69d89",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Apply a function to a DataFrame : ``isna().sum()``\n",
    "\n",
    "The ``.sum()`` method performs a sum on an entire DataFrame. When performing sums, boolean values are treated as 1 if they're ``True`` and 0 if they're ``False``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaf90c2-551b-4179-99c2-24a5c33efe96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edea25a-e192-4601-9b7d-2330709c1dea",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**>>>** How many missing values in our DataFrame ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9b8df2-a36e-4e29-bea0-1970528a7c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1486a434-ceae-4d7d-9a0d-05583385e4dd",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "# Series\n",
    "\n",
    "The output generated by ``.isna().sum()`` is called a Series. A Series is a one-dimensional labeled array-like data structure, it is sometimes referred as \"column\". A Series consists of two main components:\n",
    "\n",
    "- **Values**: This is the actual values contained in the Series, which can be of any data type such as integers, floats, strings, or more complex types.\n",
    "\n",
    "- **Index**: An index is a label or identifier associated with each data point in the Series.\n",
    "\n",
    "DataFrames are a collection of Series, so if you slice your DataFrame using the name of the columns, you'll also get Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422f6c3a-3511-49b8-9b04-e9d68fd33256",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['letter']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3f3b17-16e0-46e8-ae70-24241c19ae64",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "You can tell it's a Series because there's only one dimension, and, unlike a DataFrame, the output is plain text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85eccab-2620-4866-b255-4ac11cc4d59c",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**>>>** Slice the column \"city\" from your DataFrame and display the corresponding Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d08193a-3eeb-4115-b30c-c48ba89887d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efec20ba-9c90-4cc1-9f84-910ed3767572",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Creating or replacing Series\n",
    "\n",
    "Just like a dictionnary, to create or replace a Series you just have to assign it a value  or an object (list, dict, integer, almost any objects...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9525759-4c0d-48fa-acfa-a0b23131b144",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['one'] = 1\n",
    "fake_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e175db06-f1f6-4d4d-b5b8-9ec227d68687",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['one'] = 999\n",
    "fake_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5ec72a-d3db-4149-835c-d835a087ccd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df[['one', 'two']] = 1\n",
    "fake_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9778e2da-4d75-4ec1-8d75-1e872b63c2ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df[['one', 'two']] = 1, 2 # An implicit tuple\n",
    "fake_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67319b7e-ba24-4a02-b411-6ad5259198c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['three'] = fake_df['one'] + fake_df['two']\n",
    "fake_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f010a02-fbe0-496d-a763-ce22d1b7ee72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['count'] = [el for el in range(fake_df.shape[0])]\n",
    "fake_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23040353-8deb-4fe8-b8fe-e2e08b2677cb",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Dropping a Series\n",
    "\n",
    "There are several ways to \"drop\" (erase / remove / delete) a Series from your DataFrame, one of the easiest is just:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60751b9e-d3a5-4e1d-9a7b-595844fe3173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.drop(columns='one') # This function is not \"in place\" which means we haven't modified \"fake_df\" yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4608925c-518b-4335-9910-40933ed2bff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we're happy with the result\n",
    "# We can replace the old df with the new one\n",
    "fake_df = fake_df.drop(columns='one')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb0f2fd-06b8-4754-9b77-817763ed724c",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**/!\\ WATCH OUT !** This time we're not replacing or creating a **Series** we're replacing the whole DataFrame!\n",
    "\n",
    "One can get confused very easily. Luckily if you make a mistake, it's also very easy to go back and re-run the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc509bcc-4ace-43f1-a8b9-70da712de17d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can drop several columns by passing a list.\n",
    "fake_df.drop(columns=['two', 'three', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17afb14c-e8e5-4679-9751-db6ac515bf7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If we're happy with the result\n",
    "# We can replace the old df with the new one\n",
    "fake_df = fake_df.drop(columns=['two', 'three', 'count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bec7a2c-6700-44cd-9e68-c0e20da92616",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "# Dealing with data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3093926c-7015-498b-8d4b-ac076fe75223",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Setting the right data types\n",
    "\n",
    "Now that we know what is a DataFrame and a Series, and before we start doing something else, it's important that our Series are converted in the right type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc7ceb1-c9b9-43ac-941a-5e49e1802ab0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc597c7-c520-4d2d-8267-9532589f8c8b",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Conversion with `.astype()`\n",
    "\n",
    "There are many different types of dtype. Some of them use standard Python format, some are specific to Pandas and others are common to several other languages (PyArrow).\n",
    "\n",
    "Here let's use either:\n",
    "\n",
    "- `'string'` (which is a Pandas type)\n",
    "- `'category'` (also pandas type)\n",
    "- `int` (python type)\n",
    "- `float` (python type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63de3106-fb53-4c58-8bbe-e21c3dc5df04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# One conversion\n",
    "fake_df['letter'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2da2ed-076f-400f-81e7-fdac83d9d871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Several conversions\n",
    "fake_df[['fruit', 'letter']].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e62766-f253-4362-9e0c-586f65994450",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replacing old Series with new ones\n",
    "fake_df[['fruit', 'letter']] = fake_df[['fruit', 'letter']].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba88b606-632a-4d7e-a484-cbad6315be23",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Conversion with a new import\n",
    "\n",
    "The best practice is probably to set the datatypes when importing the data. This is specially true when we work with large databases because dtypes as `category` for example use less memory than string.\n",
    "\n",
    "When using the funcion `pd.read_csv()`, we can give to the argument `dtypes` a dictionary with column names as keys and dtype as value. We can either type this dictionary or use dict comprehension to generate a template and then edit it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2151d5-18af-4b18-90e2-c756f2abc24d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "{col : 'string' for col in fake_df.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7bc850-7926-470d-8148-197e0248875c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# copy / paste and edit:\n",
    "d = {'letter': 'category',\n",
    "     'fruit': 'category',\n",
    "     'value': 'float32',\n",
    "     'numbers_list': 'string',\n",
    "     'date': 'string'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287c96a7-a918-4fd4-8a34-12d4d7eae913",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df = pd.read_csv(\"data/fake.csv\", dtype=d)\n",
    "fake_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1271571-2125-41e5-b70b-080586b38dc4",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**Note**: If a column is not in the dictionary provided to `pd.read_csv()`, Python will try to infer the dtype."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c4a277-7800-460a-ad40-9a361c5458ce",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**>>>** Set the right dtypes for the survey DataFrame (df).\n",
    "\n",
    "- \"city\", \"dept\", \"size\", \"animals\", \"colour\", \"time\" will be 'string' (for now).\n",
    "- \"salary\" can be 'int32' to save up a little bit of memory.\n",
    "- \"gender\" and \"age\" will be 'category'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e69939-372c-4e14-a193-b18696438d97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d671d2-c0b9-4d73-b7f4-64e744583823",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Time format\n",
    "\n",
    "Our \"df\" and \"fake_df\" both contain dates. However if you take a look at it, they're only strings, not dates yet. Pandas can use \"datetime\" objects allowing us to plot and perform operations on them.\n",
    "\n",
    "In order to do so, we can use the function ``pd.to_datetime()`` which will convert our strings to the right format. Sometimes Pandas will be able to infer automatically the date format. But in this case the strings are not standards so we need to pass a *strftime* (string format time) to the parameter \"format\" to tell Python what's the format date.\n",
    "\n",
    "Each % following by a letter means Python is going to replace it with the elements it finds. The next letter that follows the \"%\" is code, the rest of it is just characters which will be erased when converting to the datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674139db-c83a-400e-abb6-6b69efa530ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.to_datetime(fake_df['date'], format='%Hh:%Mm:%Ss %d-%b-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff993a2-f00b-4a0a-ac31-15b504cc433d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Once we're happy with the result, let's create a new Series\n",
    "# that will contain the date in the right format\n",
    "fake_df['date'] = pd.to_datetime(fake_df['date'], format='%Hh:%Mm:%Ss %d-%b-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb025ab2-2fec-448a-96de-66bd76f75022",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can now perform operations on this Series\n",
    "fake_df['date'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32195bea-4c5b-40f4-96ba-19ad5e10d26f",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## The Series \"time\"\n",
    "\n",
    "**>>>** Replace the Series \"Time\" with a new one using the function `pd.to_datetime()` and the right *strftime* that will store our dates with in datetime format.\n",
    "\n",
    "To better understand how a *strftime* is used, move the edit cursor inside the function's name, then press \"shift+tab\". It will open the \"doc string\" which contains a lot of useful informations. There's a link inside the \"format\" section, follow the link, it will take you to the pandas documentation (go to the bottom of the page).\n",
    "\n",
    "**>>>** Then find the minimum value, the maximum value and the mean of the \"datetime\" Series we've just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46291f50-0aa4-4413-bdef-6ed6d48259cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df['time'][0]) # Checking what the first line looks like\n",
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ccf58c-e8d8-4ce6-a942-eecc4aaf15b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When you're done, replace the old Series with the new one here\n",
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d150ed3-bd81-44b2-bda8-954b84e2b1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the min:\n",
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c74e47a-67ae-4779-9021-d33e02238261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the max:\n",
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33729ba-e9c6-4be5-9dfe-dcfd9600321c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display the mean:\n",
    "# Code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26f29a0-9c32-472f-8459-0fad19d5b462",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Plotting data\n",
    "\n",
    "Let's go back to our fake_df. You can plot a Series like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb61f2fe-2c90-46e5-8d50-1916d77c4e95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['value'].plot(); # Adding a semicolon removes useless legend\n",
    "# Note that line stops as soon as it encounters a missing value (NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c45fd3b-a278-4461-9de7-1c8fefb8d27d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can specify what graph you want with the 'kind' parameter.\n",
    "# Let's use a bar graph first.\n",
    "# Bar graphs are usually used to plot categorical data.\n",
    "# As we want to plot the value for each row of our fake_df, this would work.\n",
    "\n",
    "fake_df['value'].plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8fec7d-abd7-47a2-ba9b-2dd2e9e32da6",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "But the xticks are the index of our DataFrame. Let's plot some values as \"y\" and some categorical values as \"x\". In order to do this, you can use ``.plot()`` directly on a DataFrame, allowing you to manipulate multiple Series easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3050d33a-eee0-471c-8237-987faf10ecb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.plot(x='letter', y='value', kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d9a7c1-d225-405a-be9c-f60f15d98966",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## The Series \"salary\"\n",
    "\n",
    "**>>>** Plot both the Series 'city' and 'salary' on the same graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f947f80-bd8e-4e1b-960f-0013e1e01103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db477883-c846-4418-b868-f01728a5bcfd",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Operations on numeric data\n",
    "\n",
    "The Series **'value'** in *fake_df* and **'pop_clean'** in *df* are both numerical data. Meaning you can apply many different statistical functions on them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aa559c-f705-4cf8-9044-a7507e02bbad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['value'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51097083-14fb-4d0a-b5f9-a43a347f52eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['value'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97435c2-3e68-4556-86d7-d15463bd155a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['value'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ad4ae9-2cbc-43d2-802d-ad9b0007ff00",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**>>>** Have a look at basics statistics on the \"salary\" data. You can use the function `.astype(int)` to convert the result to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646d00bc-4119-4799-a9c0-e4748cededa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48136f52-d367-443c-b8fc-b83ffbf254f7",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Selecting data in Pandas : ``.iloc[]`` and ``.loc[]`` methods\n",
    "\n",
    "The `.iloc[]` and ``.loc[]`` methods in Pandas are used for indexing and selecting data in DataFrames. They serve different purposes and work based on different indexing schemes:\n",
    "\n",
    "### The ``.iloc[]`` method (Integer Location)\n",
    "\n",
    "``.iloc[]`` is primarily used for selecting data by integer position, which means you specify row and column positions numerically :\n",
    "\n",
    "- It accepts integer-based indexing for both rows and columns.\n",
    "- The indexing is zero-based, similar to Python lists.\n",
    "- You can use integers, slices, lists, or boolean arrays to select data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35f01b8-a86c-4f05-a599-6c76a0695b39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.iloc[0]  # Select the first row\n",
    "# Note that it returns a Series, not a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50d759b-2e2b-41de-888a-ce173aec7865",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.iloc[2:5, 1:3]\n",
    "# Returns a DataFrame because they are several Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2b63cc-63f8-4005-b187-d4714da01e01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.iloc[[0, 3, 5], [1, 2]]  # Select specific rows and columns by integer positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20095383-60b7-4c17-9830-6487cacc3b2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select specific rows and columns with boolean indexing\n",
    "fake_df.iloc[[True, False, True, False, True, True, False, True, False, True, False], [False, True, True, False, True]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b93652-37a0-4b7c-8f6c-4f65ec8c417e",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### The ``.loc[]`` method (Label Location)\n",
    "\n",
    "The method ``.iloc[]`` can sometimes be useful, but generally we use the ``.loc[]`` method which is very powerful. It allows us to select data by label or label-based conditions.\n",
    "\n",
    "- It accepts label-based indexing for both rows and columns.\n",
    "- Unlike most of the indexing in Python : the indexing is **inclusive on both ends** (i.e., slices include the specified labels).\n",
    "- You can use labels, slices, lists, or boolean arrays to select data.\n",
    "- You can filter using conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e9a9e0-87e2-4127-bce0-c16809e43279",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.loc[0:3, 'fruit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c11aa22-154e-481d-ba4c-2fb912fe9fcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.loc[1:2, ['fruit', 'date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16a0141-fe09-422d-ba37-3361e893c061",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Just like .iloc[], you can filter rows and columns using boolean indexing\n",
    "fake_df.loc[[True, False, True, False, True, True, False, True, False, True, False], [False, True, True, False, True]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ca1d22-e06a-4b77-a559-8e0cf247527c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pandas returns a boolean Series when you make comparison\n",
    "fake_df['value'] > 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b9da22-2c05-497b-b52d-dddf00b5de81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can use this boolean Series to filter your DataFrame using .loc[]\n",
    "fake_df.loc[fake_df['value'] > 500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c615cf7d-a34c-4f62-b267-cbc6e3b3f104",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Let's fix the Series \"salary\"\n",
    "\n",
    "**>>>** Let's remove the outlier in the Series salary.\n",
    "\n",
    "- Choose a threshold , remove the outliers using ``.loc[]`` and compute the same stats.\n",
    "- Generate a new graph without the outliers.\n",
    "\n",
    "**TIP**: When using a hist graph, you can decide the numbers of \"columns\" using the \"bins\" parameter. Default is set to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25e1fd1-f740-4fde-a4d1-f4953e3e0f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bad50b-4aa1-4cd6-baa8-9c7650d5151c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393d1c70-4fe1-41d7-91b4-462c349a2fb9",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Plotting categorical data\n",
    "\n",
    "If we try to plot a non-numeric Series, we get an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c214dc31-d092-4646-93b7-74022480535e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Yields an error!\n",
    "#df['country'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d83d280-4015-4692-ad72-3a3845492635",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### The method ``value_counts()``\n",
    "\n",
    "This method is very useful, it takes as input almost any Series and return a new Series which displays the number of occurrences for each elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a5d18a-5fcf-4546-b77a-a0321edf758a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['letter'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e5037c-2c60-45ad-a5c3-27d79559ae87",
   "metadata": {},
   "source": [
    "## The Series \"city\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cae2df-f2a5-4e76-b041-beaf19ff121f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['city']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7adca6f-3101-405f-b49a-05d5bdcef9ae",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**>>>** Use the ``.value_counts()`` method and plot the \"country\" Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb0622c-0a33-44cf-8b76-3db072e1e46c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f5c55b-b7dd-458d-8d2e-37b9d6910d00",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**>>>** This works, but it's not ideal. Check the [online documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html) and give better arguments to the parameters of the `.plot()` method in order to display a useful graph. You're probably going to use the parameter \"kind\", and maybe \"rot\" (rotation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63bfa99-5012-4fcb-96bc-bcfb5412889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eb6d04-dd16-4305-a2dd-88f735539863",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## String manipulation\n",
    "\n",
    "As you can see some cities names start with a capital letter, and some others are lower-case. Pandas provides many functions to work with strings. They are in a submodule called `.str`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae70196c-4f89-4140-b3de-6f06c8f706e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['letter'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e4e9ab-f272-401b-b74f-3f710b4fbab6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['letter'].str.replace(\"D\", \"The function can also be used!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d298cabe-f531-4092-b2c5-5596b403b031",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Fixing the strings in the Series \"city\" \n",
    "\n",
    "**>>>** Capitalize the strings inside the Series \"city\". When it's done, replace the old Series with the new one and plot the data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1c49ad-3c75-44f4-8b3b-6442d98a40cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bf24fa-c37b-4cf6-99c6-0bef8f8755e5",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "# Group By and Aggregations\n",
    "\n",
    "## Group By\n",
    "\n",
    "\n",
    "In data science, a \"Groupby\" is an operation that involves splitting a dataset into groups based on one or more criteria. It is a way to break down data into smaller, manageable pieces for analysis.\n",
    "\n",
    "Once data are separated in different groups, we usually apply one or several functions on each different group.\n",
    "\n",
    "## Aggregations\n",
    "\n",
    "\n",
    "\"Aggregations\" refer to the process of applying a mathematical or statistical function to a set of data to obtain a single summary value. Aggregations typically involve operations like sum, mean, median, count, min, max, etc.\n",
    "\n",
    "Aggregations are used to summarize and condense data, providing insights into the overall characteristics of a dataset or specific groups created using groupby.\n",
    "\n",
    "## Exemples\n",
    "\n",
    "Let's imagine we have a library with several books classified with their genre. We can group them and apply the function `.sum()` to check how many books we have for each different categories.\n",
    "\n",
    "<img src=\"files/group_by-sum.jpg\" width=\"90%\" align=\"center\">\n",
    "\n",
    "But we could also apply the function `.mean()` to compute the average.\n",
    "\n",
    "<img src=\"files/group_by-avg.jpg\" width=\"100%\" align=\"center\">\n",
    "\n",
    "[Source](https://learnsql.com/blog/group-by-in-sql-explained/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57d003a-fce8-41e1-91f1-0ca6c1aa655d",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Performing GROUP BY on our datasets\n",
    "\n",
    "### A simple Group By\n",
    "\n",
    "We can create groupby objets without applying a function, and save it for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79ea7e4-1021-49d7-8ba2-ebed273cbdbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.groupby('letter', observed=False) # Data have been grouped by Letter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20247098-19cd-406e-8ab5-eb7ab5cbbefe",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Simple functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f03181-d683-4beb-b568-071f142271af",
   "metadata": {},
   "source": [
    "#### ``.sum()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a09f50-e8c3-4478-96ee-f859ae5ef807",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.groupby('letter', observed=True).sum('value')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591edab5-d235-42cc-a378-6b420facfda1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### ``.count()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab19cf5d-7b2d-4b7e-9292-7fa95b265b6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's use a count()\n",
    "fake_df.groupby('letter', observed=True).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c71a2a2-70b4-4c90-97b0-ccb2ff0aea55",
   "metadata": {},
   "source": [
    "#### ``.mean()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee6044c-c974-440f-a5b6-b703930cc35e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.groupby('letter', observed=True).mean('value')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8e283d-4322-40d5-b546-f618a64f74a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### The method ``.agg()``\n",
    "\n",
    "\n",
    "The .agg() method in Pandas is used to perform aggregation operations on a DataFrame or Series.\n",
    "\n",
    "We can specify one or more aggregation functions that we want to apply to the data. These functions can be built-in functions like ``sum()``, ``mean()``, ``min()``, ``max()``, or custom functions.\n",
    "\n",
    "It can take strings arguments, lists or even dictionaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e7503c-9fd5-4bc4-9536-fb2b8a23bd84",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### ``.agg()`` with one function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a11aa2-1023-4eb8-8b25-53fd196a1c6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.groupby('letter', observed=True).agg('mean', numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24af80c6-c0eb-4a94-9e2f-b8e5f7a13a05",
   "metadata": {},
   "source": [
    "#### ``.agg()`` with several functions\n",
    "\n",
    "Here we took only the Series \"value\" from the grouped data, and apply three different functions to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666205ad-a1cb-45e1-a818-23b25878d479",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.groupby('letter', observed=True)['value'].agg(['count', 'sum', 'mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db9cac7-6f7b-4bb3-b32a-c9d3c38ec422",
   "metadata": {},
   "source": [
    "#### ``.agg()`` with a dict of arguments\n",
    "\n",
    "Passing a dictionnary of arguments allows us to better control the behavior of the aggregation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557ae342-4184-44ac-9110-b2659df2c5ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.groupby('letter', observed=True).agg({\n",
    "        'value' : ['mean','median', 'max', 'min'],\n",
    "        'fruit':  ['count']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cadd7b-9092-4d0a-a5ef-cd7544c4fa1c",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "Let's check if the the expected salary has a relation with the gender.\n",
    "\n",
    "**>>>** Create a new df named \"salary_df\" in which there is no outlier values.\n",
    "\n",
    "**>>>** Group the data by gender and compute the mean of the salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1598b0-5728-4733-b270-30bd5fb9aaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ada3b2-21d7-472a-9320-b0e5d1128b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d975e77-01a4-4415-a2c1-939b74195744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c5bbb7-2806-4308-926c-b39cfd2b90db",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## The `.map()` method\n",
    "\n",
    "The ``.map()`` method in Pandas is used to apply a function in a Series. The result is a new Series with transformed values based on the function.\n",
    "\n",
    "Let's see some examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97719de-8aa9-48b6-9f70-28206de20c79",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "### Using a custom function with `.map()`\n",
    "\n",
    "Once we've created a function, `.map()` will apply the function on each element and returns a new Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24c3b5f-47aa-4662-899b-b04b1e9f48f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's define a function\n",
    "def adds_1000(number):\n",
    "    return number + 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a053d5b-230b-4ee9-bbae-de2e22cb99f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "adds_1000(123.53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5c9cfd-8588-4adc-a00a-c4f6239bc76b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['value'].map(adds_1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7417227-bde6-43ba-b565-9963d2038ef9",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "# The Series \"size\"\n",
    "\n",
    "Let's say we want to know what is the average size of the people who took the survey. We first need to clean and convert those strings in integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a037d6e6-d5b1-4b75-b7ee-277507dfce88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['size']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caa491e-3f85-4bbb-a79c-65f0c22b0df2",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**>>>** Write a custom function that clean the Series.\n",
    "\n",
    "- Apply it using `.map()`\n",
    "- Replace the old Series with the new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a254790-1b41-46ce-8b0b-f25e1d52961a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8ab690-2c99-4aa7-96bb-b35caaf5148c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fd0f07-0621-41c1-abc3-b09fc797df12",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "# Join\n",
    "\n",
    "Joins allow us to retrieve data from other sources and add them to our existing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eff4af-e234-4b7a-aed1-63c51d5226ac",
   "metadata": {},
   "source": [
    "<img src=\"files/left-outer-join-operation.png\" width=\"50%\" align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16ad7dd-e9fd-483a-9ba6-b31bb364a208",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fruits_df = pd.read_csv(\"data/fruits_kcal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab09a466-e554-4c91-abdc-2a38c64937b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fruits_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87da085-7072-4864-bf5e-83baaf90ed93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df.merge(fruits_df[\"calories (per 100g)\"], left_on=\"fruit\", right_on=fruits_df[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0324540d-f4fc-486d-897f-daee02b26d4c",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## Adding Countries Populations\n",
    "\n",
    "Let's use a join to add the population of each country.\n",
    "\n",
    "**>>>** Download the data or read it with Pandas from this [URL](https://raw.githubusercontent.com/samayo/country-json/master/src/country-by-population.json)\n",
    "\n",
    "**>>>** Store the data in a df called \"pop_df\".\n",
    "\n",
    "**>>>** Perform a join on the country name between \"df\" and \"pop_df\" to retrieve the population of each country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237fdc9d-1bcb-4075-81d5-7b1db7f29004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8264c2bf-f27f-4263-af96-e8f584d0a7f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6ea10a-a076-4899-8119-b1974cda98b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd54a4c3-add6-4e8d-a095-d31e64031c16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078df316-8b68-49b3-8f28-e120d26054d4",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "## The function `.str.split()`\n",
    "\n",
    "This function belongs to the submodule `.str`. It behaves almost the same way than the `.split()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff09118c-3892-4792-a2b7-1ab7a8d68bd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['numbers_list'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6176a415-734f-40a9-8ac0-b684db47da74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['numbers_list'].str.split()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcb60d1-7073-4b25-89d6-dd06f9ac66de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['numbers_list'].str.split('-')[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f562d6-c5a2-4b94-86c1-9b2a33fe77f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['numbers_list'].str.split('-', expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbb8bb2-592c-4f11-9fb4-b3bbe45bbcbe",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "# The Series \"animals\"\n",
    "\n",
    "This Series has an issue. Several data are stored in the same string. Let's separate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68505e2-e90d-4cca-b1c3-644bc411e2f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['animals']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268bdbdd-b42f-49cd-8bdf-0d62da994f83",
   "metadata": {
    "tags": [
     "en"
    ]
   },
   "source": [
    "**>>>** To deal with this data, we'll need to: \n",
    "\n",
    "- Put all the strings in lower case.\n",
    "- Find the right separator.\n",
    "- Split our data in three different Series named \"animal1\", \"animal2\" and \"animal3\". In order to do this use the parameter \"expand\"\n",
    "\n",
    "**TIP** : You can give a list of Series to a Dataframe. For example:\n",
    "\n",
    "```Python\n",
    "fake_df[['letter', 'value']]\n",
    "```\n",
    "It might be useful to create new Series in a single line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b78687c-8880-4015-b4f6-cc296d1e8c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a1a5c0-78d4-4df6-a3f5-3a193239f634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to create the 3 Series \"animal1\", \"animal2\" and \"animal3\"\n",
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dc7ff6-6f57-4d41-8dfc-2b001ae77842",
   "metadata": {},
   "source": [
    "# The Series \"age\"\n",
    "\n",
    "**>>>** Plot the data using a bar graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b480810e-5f5f-4011-8bdf-67460e9b0459",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df04aa58-eaf1-41ec-96ef-0466889b38a8",
   "metadata": {},
   "source": [
    "## The methods `.unique()` and `.nunique()`\n",
    "\n",
    "### `.unique()` \n",
    "\n",
    "- The `.unique()` method is used to return an array of all the unique values present in a Series. In other words, it removes duplicate values and provides a list of unique values.\n",
    "\n",
    "- It returns a new Series.\n",
    "\n",
    "### `.nunique()` \n",
    "\n",
    "- The `.nunique()` method is used to count the number of distinct (unique) values in a Series.\n",
    "\n",
    "- It returns the count of unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064032cc-61bf-4043-b0aa-ee90d61d46bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['letter'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed42e7e9-a481-4929-8a13-638abecc5f4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_df['letter'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b503d721-2cbe-4132-9614-bdd62c3731c1",
   "metadata": {},
   "source": [
    "## Creating a new Series : \"gender_int\"\n",
    "\n",
    "**>>>** Create a new Series called \"gender_int\", and assign 1 if the gender is \"Woman\" and 0 if the gender is \"Man\". Convert this Series to 'int'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08995cc3-08e7-447f-ac50-f721c63726e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d07d45-5ca5-422c-84fc-b0749de624dc",
   "metadata": {},
   "source": [
    "## Creating a new Series : \"age_mean\"\n",
    "\n",
    "**>>>** Create a new Series called \"age_mean\" which will take the mean of each age group. There are several ways to do it:\n",
    "\n",
    "- Use a dictionary and `.map()` (quick and simple way).\n",
    "- Use `.unique()` to get all the unique strings, convert the elements in integer and compute the mean. You can either use a custom function or a comprehensive dictionary. To compute the mean, you can use `np.mean()` (more complicated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fedb261-3ad4-47a9-8fc6-764ae1ef833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d8cafc-2da7-4dfd-9fa8-73f65c12d6ba",
   "metadata": {},
   "source": [
    "# Correlation\n",
    "\n",
    "Let's see if we can find any correlation in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd985e78-7cd5-44b6-8281-3a45b56aa1ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455ac7a9-a942-4152-ae17-5efbfe1eca85",
   "metadata": {},
   "source": [
    "## Prepare the dataset\n",
    "\n",
    "First let's create a view of our df with only the variables of interest such as:\n",
    "\n",
    "- 'salary'\n",
    "- 'age_mean'\n",
    "- 'size'\n",
    "- 'gender_int'\n",
    "\n",
    "### The method `.copy(deep=True)`\n",
    "\n",
    "When we slice our DataFrame, it creates a **view**, not a **copy**. However you can force Pandas to create a distinct copy using `.copy(deep=True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db9b86b-ad2d-4182-b714-5b63fdb64576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_fake_df = fake_df.copy(deep=True)\n",
    "new_fake_df['letter'] = \"Z\"\n",
    "new_fake_df['letter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83662be6-2f6f-4edc-b355-094d9b9788e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Original df hasn't been modified\n",
    "fake_df['letter']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2af02a8-458e-490b-a272-b16022cccc56",
   "metadata": {},
   "source": [
    "**>>>** : Create a deep copy of our DataFrame named \"corr_df\" which contains only those columns of interest. Then apply the `.corr()` method on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65830b4-a3d6-4fd5-894d-d503cbd59a32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadcdfc3-aee2-4ceb-8fdc-d03addbc7e48",
   "metadata": {},
   "source": [
    "## An other way to deal with outliers.\n",
    "\n",
    "We still have some outliers, especially inside the Series \"salary\". There are countless ways to remove them, let's use `np.where()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0b7150-6ea7-4f4c-936f-d836e5714005",
   "metadata": {},
   "source": [
    "### `np.where()`\n",
    "\n",
    "This function provides a way to perform conditional operations on NumPy arrays and Pandas Series. It allows you to generate a new array or a new Series based on a specified condition. The general syntax for `np.where()` is:\n",
    "\n",
    "```python\n",
    "np.where(condition, value_is_true, value_if_false)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f72b010-9014-4cc3-a82a-4eabdb650499",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Exemple\n",
    "\n",
    "np.where(fake_df['value'] > 0, 10, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b5ab29-b3b0-4c34-b94c-2a1c4cec6b1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Exemple\n",
    "\n",
    "# np.set_printoptions(precision=2, suppress=True) # useful to better visualize\n",
    "np.where(fake_df['value'] > 0, 10, fake_df['value'] / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3db35e5-fc48-4c79-a221-603bc480cf0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating or replacing a Series\n",
    "\n",
    "fake_df['new_value'] = np.where(fake_df['value'] > 0, 10, fake_df['value'] / 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66159f4-f871-4265-b48e-ece18f0a5e93",
   "metadata": {},
   "source": [
    "**>>>** Replace the two outliers values we have in the \"salary\" Series with the median of that Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2d6d94-1ab0-4d4a-9bec-78dba8e0503d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cc6456-88c3-42de-b454-d4dc1bd78e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's display the ne result\n",
    "corr_df.corr()#.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2719ded-6c54-4b59-95fb-692df1cfc8fd",
   "metadata": {},
   "source": [
    "# Correlation visualisations\n",
    "\n",
    "When dealing with data, it's always a good thing to look at the data and not just numbers.\n",
    "\n",
    "## Anscombe's quartet\n",
    "\n",
    "Anscombe's quartet comprises four data sets that have nearly identical simple descriptive statistics, yet have very different distributions and appear very different when graphed. ([wikipedia](https://en.wikipedia.org/wiki/Anscombe%27s_quartet))\n",
    "\n",
    "\n",
    "<img src=\"files/anscombe.png\" width=\"70%\" align=\"center\">\n",
    "\n",
    "\n",
    "| Property                                                  | Value             | Accuracy                                |\n",
    "|-----------------------------------------------------------|-------------------|-----------------------------------------|\n",
    "| Mean of x:                                                | 9                 | exact                                   |\n",
    "| Sample variance of x:                                     | 11                | exact                                   |\n",
    "| Mean of y:                                                | 7.50              | to 2 decimal places                     |\n",
    "| Sample variance of y:                                     | 4.125             | 0.003                                  |\n",
    "| Correlation between x and y:                              | 0.816             | to 3 decimal places                     |\n",
    "| Linear regression line:                                   | y = 3.00 + 0.500x | to 2 and 3 decimal places, respectively |\n",
    "| Coefficient of determination of the linear regression: R | 0.67              | to 2 decimal places                     |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf59c64-0b69-41cf-8495-4781621a2954",
   "metadata": {},
   "source": [
    "## Seaborn and heatmap\n",
    "\n",
    "Let's use Seaborn, a libray built on top of matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f110e0-7a6d-4661-b121-b10ecafd713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(corr_df.corr());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f815d9-915e-4c22-b08b-b3aa1ce2c49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's annot the heatmap and make it range from -1 to 1.\n",
    "sns.heatmap(corr_df.corr(), vmin=-1, vmax=1, annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7315d93-bf54-4717-a005-1569fe65bf16",
   "metadata": {
    "tags": []
   },
   "source": [
    "### The `sns.pairplot()` function\n",
    "\n",
    "This function is used to create a matrix of scatterplots, also known as a pairwise scatter plot matrix. It's a valuable tool for visualizing the relationships between multiple variables (columns or Series) in a DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28c38e6-5fc6-41ee-a5f4-56130ce366a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(corr_df, diag_kind='kde', kind='reg', plot_kws={'color': 'red'});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199853b3-38cf-4bf8-92a5-c8e21507376b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='gender_int',\n",
    "           y='salary',\n",
    "           data=corr_df,\n",
    "           fit_reg=True,\n",
    "           line_kws={'color': 'red'}\n",
    "          );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba358a9-4bbd-4ebc-9922-d583840c6736",
   "metadata": {},
   "source": [
    "## Export\n",
    "\n",
    "You can export your df to various format such as CSV, Excel, JSON and so on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00494dec-5dd6-44c8-8f65-80ba25ea16fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# csv\n",
    "df.to_csv('df_export.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a254b11-fcc9-420e-b75a-210b4772e06e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#json\n",
    "df.to_json('df_export.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
